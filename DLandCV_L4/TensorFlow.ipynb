{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глубокое обучение на TensorFlow\n",
    "\n",
    "Вы написали много кода во второй части задания, чтобы реализовать весь набор функций нейронной сети. Dropout, блочная нормализация и двумерные свертки являются рабочими лошадками глубокого обучения в компьютерном зрении. Вы также приложили много усилий, чтобы сделать ваш код эффективным и векторизованным.\n",
    "\n",
    "Однако в последней части этого задания мы отложим ваш прекрасный код и вместо этого перейдем к одной из двух популярных платформ глубокого обучения: в этом случае TensorFlow (или PyTorch, если вы перейдете соответсвующему блокноту)\n",
    "\n",
    "\n",
    "#### Что такое TensorFlow?\n",
    "TensorFlow - это система для вычислений над тензорными объектами с использованием вычислительных графов  и поддержкой выполнения обратного распространения. Тензоры представляют собой n-мерные массивы, аналогичные numpy ndarray.\n",
    "\n",
    "#### Зачем изучать  TensorFlow?\n",
    "* Наш код теперь сможет исполняться на графических процессорах! В этом случае обучение будет проходить гораздо быстрее. \n",
    "* Мы хотим, чтобы Вы были готовы использовать один из развитых фреймворков для своих проектов, чтобы Вы могли проводить эксперименты эффективнее, чем если бы Вы писали каждую функцию вручную.\n",
    "* Мы хотим, чтобы Вы стояли на плечах гигантов! TensorFlow и PyTorch - отличные фреймворки, которые сделают вашу жизнь намного проще.\n",
    "* Мы хотим, чтобы Вы  ознакомились с подходом к кодированию глубокого обучения, который применяется  в академических кругах или в промышленности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как изучать TensorFlow?\n",
    "\n",
    "Есть много прекрасных руководств по изучению  TensorFlow, включая руководство Google (https://www.tensorflow.org/get_started/get_started).\n",
    "\n",
    "Этот блокнот также послужит Вам руководством, что вам нужно сделать, чтобы обучать модели в TensorFlow. Просмотрите в  конце этого блокнота некоторые ссылки на полезные руководства, если вы хотите узнать больше или если Вам требуются дополнительные разъяснения.\n",
    "\n",
    "\n",
    "# Содержание\n",
    "\n",
    "Этот блокнот состоит из 5 частей. Мы будем рассматривать  TensorFlow на трех разных уровнях абстракции, что должно способствовать лучшему пониманию.\n",
    "\n",
    "1. Подготовка: загрузка множества данных CIFAR-10.\n",
    "2. Базовый интерфейс (barebone) TensorFlow: непосредственный интерфейс (barebone) вычислительных графов TensorFlow.\n",
    "3. Модель интерфейса Keras: модель интерфейса  `tf.keras.Model` для определения произвольной архитектуры нейронной сети.\n",
    "4. Последовательный интерфейс Keras Sequential: удобный интерфейс `tf.keras.Sequential` для определения линейной структуры сети прямого распространения.\n",
    "5. Решение задач с использованием CIFAR-10: построение собственной сети, чтобы получить максимально возможную точность классификации для базы изображений CIFAR-10. Вы можете экспериментировать с любым слоем, оптимизатором, гиперпараметрами или другими расширенными функциями.\n",
    "\n",
    "Сравнительная таблица:\n",
    "\n",
    "| Интерфейс     | Гибкость    | Простота    |\n",
    "|---------------|-------------|-------------|\n",
    "| barebone| Высокая     | Низкая      |\n",
    "| `tf.keras.Model`     | Высокая| Средняя   |\n",
    "| `tf.keras.Sequential`| Низкая | Высокая   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть I: Подготовительная\n",
    "\n",
    "Сначала загрузим набор данных CIFAR-10. Это может занять несколько минут для загрузки при первом запуске, но после этого файлы должны быть кэшированы на диске, а загрузка должна быть быстрее.\n",
    "\n",
    "В предыдущих частях задания мы использовали специфический код для загрузки и чтения набора данных CIFAR-10; однако пакет `tf.keras.datasets` в TensorFlow предоставляет предустановленные  утилиты для загрузки многих распространенных наборов данных.\n",
    "\n",
    "Для целей  задания мы по-прежнему будем писать собственный код для предварительной обработки данных и итерации на данных по мини-блокам. Пакет `tf.data` в TensorFlow предоставляет инструменты для автоматизации этого процесса, но работа с этим пакетом создает некоторые сложности и выходит за рамки этого задания. Однако использование `tf.data` может быть намного эффективнее, чем простой подход, используемый в этом блокноте, поэтому вы должны использовать его в своих проектах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Извлекает набор данных CIFAR-10 из Интернета и выполняет предварительную\n",
    "    обработку данных для двухслойного нейроклассификатора. \n",
    "    Это те же шаги, что мы использовали для SVM и которые собраны в одной функции.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка: объект Dataset\n",
    "\n",
    "Для нашего удобства мы определим упрощенный класс `Dataset`, который позволит нам перебирать данные и метки. Это не самый гибкий или эффективный способ перебора данных, но он будет служить нашим целям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Конструирование объект Dataset для итераций по набору данных X и по меткам y\n",
    "        \n",
    "         Входы:\n",
    "         - X: numpy массив данных любой формы\n",
    "         - y: numpy массив меток любой формы, но с y.shape [0] == X.shape [0]\n",
    "         - batch_size: целое число, указывающее количество элементов миниблока\n",
    "         - shuffle: (необязательно) Логическое значение, следует ли перетасовывать данные\n",
    "        на каждой эпохе\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "# Мы можем выполнять интерации так:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы можете опционально использовать GPU, установив флаг **USE_GPU в True** ниже. Для этого задания не обязательно использовать GPU; если вы работаете в Google Cloud, то мы рекомендуем вам не использовать графический процессор, так как аренда будет значительно дороже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  /cpu:0\n"
     ]
    }
   ],
   "source": [
    "# Set up some global variables\n",
    "USE_GPU = False\n",
    "\n",
    "if USE_GPU:\n",
    "    device = '/device:GPU:0'\n",
    "else:\n",
    "    device = '/cpu:0'\n",
    "\n",
    "# Constant to control how often we print when training models\n",
    "print_every = 100\n",
    "\n",
    "print('Using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть II: Базовый интерфейс (вarebone) TensorFlow\n",
    "\n",
    "TensorFlow поставляется с различными API-интерфейсами, которые делают его очень удобным для определения и обучения нейронных сетей; мы рассмотрим некоторые из этих конструкций в Части III и Части IV этого блокнота. В этом разделе рассмотрим создание модели с базовыми конструкциями TensorFlow, чтобы помочь вам лучше понять, что происходит под капотом базового API-интерфейса.\n",
    "\n",
    "TensorFlow, в первую очередь, - это фреймворк для  работы со **статическими вычислительными графами**. Ребрами  вычислительного графа являются тензоры, которые хранят n-мерные массивы; узлы  графа представляют собой функции, которые применяются к тензорам, когда выполняются вычисления в соответствии с вычислительным графом.\n",
    "\n",
    "Это означает, что типичная программа TensorFlow содержит в две разные фазы:\n",
    "\n",
    "1. Создание вычислительного графа, который описывает вычисления, подлежащие выполнению. Этот этап фактически не выполняет никаких вычислений; он просто создает символическое представление ваших вычислений. Этот этап обычно определяет один или несколько объектов типа «placeholder», которые представляют входные данные вычислительного графа.\n",
    "2. Многократное исполнение вычислительного графа. Каждый раз, когда граф исполняется, вы указываете, какие части графа вы хотите вычислить, и передаёте словарь `feed_dict`, который поставляет конкретные значения любому объекту ` placeholder `на графе.\n",
    "\n",
    "\n",
    "\n",
    "### Разминка с TensorFlow: функция flatten\n",
    "\n",
    "Определим простую функцию «уплощения» `flatten`, которая реформатирует данные изображений для использования в полносвязанной сети.\n",
    "\n",
    "В TensorFlow данные для сверточных карт признаков  обычно хранятся в тензоре формы N x H x W x C, где:\n",
    "\n",
    "- N - количество точек данных (размер мини-блока)\n",
    "- H - высота карты \n",
    "- W - ширина карты \n",
    "- C - количество каналов карты\n",
    "\n",
    "Это правильный способ представления данных для двумерной свертки, которая учитывает пространственные отношения между признаками изображений. Однако, когда мы используем полносвязанные слои нейронов для обработки изображений,то требуется, чтобы каждое  изображение представлялось вектором.Поэтому необходимо реформатировать изображение размером «H x W x C» в один длинный вектор. Функция реформатирования (flatten) ниже сначала определяет значение N заданного блока данных, а затем возвращает реформатированное представление этих данных. Это представление формируется аналогично методу «reshape» numpy: изменяется  размер x на N x ??, где ?? некоторое значение (в рассматриваемом случае это H x W x C, но нам не требуется указывать его явно).\n",
    "\n",
    "**ПРИМЕЧАНИЕ**: TensorFlow и PyTorch различаются своими представлениями тензоров по умолчанию; TensorFlow использует представление N x H x W x C, а PyTorch использует N x C x H x W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \"\"\"    \n",
    "    Входные данные:\n",
    "     - Тензор формы (N, D1, ..., DM)\n",
    "    \n",
    "     Выход:\n",
    "     Тензор формы (N, D1 * ... * DM)\n",
    "    \"\"\"\n",
    "    N = tf.shape(x)[0]\n",
    "    return tf.reshape(x, (N, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"Placeholder:0\", dtype=float32, device=/device:CPU:0)\n",
      "x_flat:  <class 'tensorflow.python.framework.ops.Tensor'> Tensor(\"Reshape:0\", shape=(?, ?), dtype=float32, device=/device:CPU:0)\n",
      "\n",
      "x_np:\n",
      " [[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]]\n",
      "\n",
      " [[12 13 14 15]\n",
      "  [16 17 18 19]\n",
      "  [20 21 22 23]]] \n",
      "\n",
      "x_flat_np:\n",
      " [[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17. 18. 19. 20. 21. 22. 23.]] \n",
      "\n",
      "x_np:\n",
      " [[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]\n",
      "  [10 11]]] \n",
      "\n",
      "x_flat_np:\n",
      " [[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]]\n"
     ]
    }
   ],
   "source": [
    "def test_flatten():\n",
    "    # Очистка текущего графа TensorFlow.\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "   \n",
    "    # Этап I: Определение графа TensorFlow, описывающего наши вычисления.\n",
    "    # В этом случае вычисление тривиально: мы просто хотим реформатировать\n",
    "    # Тензор, используя функцию flatten, определенную выше.\n",
    "   \n",
    "    # У нас будет один вход x. Нам еще неизвестно его\n",
    "    # значение, поэтому мы определяем объект placeholder (местозаполнитель),\n",
    "    # который будет хранить это значение,  когда граф будет исполняться. \n",
    "    # Затем этот \"заполнитель\" тензора передается функции flatten, которая вернет \n",
    "    # новый Тензор, предназначенный для  хранения плоского представления x.\n",
    "    # Вычисления на графе пока не выполняются.   \n",
    "    # Менеджер контекста tf.device сообщает TensorFlow, следует ли размещать эти тензоры\n",
    "    # на CPU или графическом процессоре GPU.\n",
    "    \n",
    "    \n",
    "    with tf.device(device):\n",
    "        x = tf.placeholder(tf.float32)\n",
    "        x_flat = flatten(x)\n",
    "    \n",
    "    # На данный момент мы просто построили граф, описывающий наши вычисления,\n",
    "    # но мы пока ничего не вычислили. Если мы напечатаем x и x_flat\n",
    "    # мы увидим, что они не содержат никаких данных; они являются тензорами TensorFlow\n",
    "    # представляющими значения, которые будут вычисляться в ходе исполнения графа.\n",
    "\n",
    "    \n",
    "    print('x: ', type(x), x)\n",
    "    print('x_flat: ', type(x_flat), x_flat)\n",
    "    print()\n",
    "    \n",
    "   \n",
    "    # Для фактического исполнения графа необходимо использовать объект Session TensorFlow \n",
    "    with tf.Session() as sess:\n",
    "        # Создаем конкретные значения входных данных x с помощью numpy\n",
    "        x_np = np.arange(24).reshape((2, 3, 4))\n",
    "        print('x_np:\\n', x_np, '\\n')\n",
    "    \n",
    "        # Исполняем вычислительный граф для вычисления конкретного выходного значения.\n",
    "        # Первый аргумент метода sess.run говорит TensorFlow, что \n",
    "        # мы хотим, чтобы он вычислил значение x_flat; feed_dict указывает\n",
    "        # значения подключаемые ко всем узлам-заполнителям нашего графа.\n",
    "        # Итоговое значение x_flat возвращается из sess.run как\n",
    "        # numpy array.\n",
    "        x_flat_np = sess.run(x_flat, feed_dict={x: x_np})\n",
    "        print('x_flat_np:\\n', x_flat_np, '\\n')\n",
    "\n",
    "        # Мы можем повторно использовать один и тот же граф для выполнения одних\n",
    "        # и тех же вычислений с различными входными данными\n",
    "        x_np = np.arange(12).reshape((2, 3, 2))\n",
    "        print('x_np:\\n', x_np, '\\n')\n",
    "        x_flat_np = sess.run(x_flat, feed_dict={x: x_np})\n",
    "        print('x_flat_np:\\n', x_flat_np)\n",
    "test_flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый  TensorFlow: Двухслойная сеть\n",
    "Теперь мы реализуем нашу первую нейронную сеть на TensorFlow: двухслойную сеть с двумя полносвязными скрытыми слоями без смещений и с ReLU нелинейностью. Пока будем использовать только низкоуровневые операторы TensorFlow для определения сети; позже мы увидим, как использовать абстракции более высокого уровня, предоставляемые `tf.keras`, чтобы упростить процесс.\n",
    "\n",
    "Определим функцию прямого распространения  `two_layer_fc`; она будет принимать тензоры входов и весов сети и возвращать тензор оценки предсказания класса. Важно помнить, что вызов функции `two_layer_fc` **не выполняет** никаких вычислений; вместо этого она просто определяет вычислительный граф  прямого пути. Чтобы фактически запустить сеть, нам нужно открыть сеанс Session TensorFlow и передать данные на  вход вычислительного графа.\n",
    "\n",
    "После определения  функции `two_layer_fc` мы проверим её реализацию, исполнив вычислительный граф, подав нули на входы сети и проверив форматы вывода.\n",
    "\n",
    "Важно, чтобы вы прочитали и поняли эту реализацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_fc(x, params):\n",
    "    \"\"\"\n",
    "    Полносвязная нейронная сеть; архитектура:\n",
    "    полносвязный слой -> ReLU ->  полносвязный слой .\n",
    "    Обратите внимание, что нам сейчас нужно только определить прямое распространение; \n",
    "    TensorFlow позаботится сам о вычислении градиентов для нас.\n",
    "    \n",
    "    Вход сети - мини-блок данных размерности (формы):\n",
    "    (N, d1, ..., dM), где d1 * ... * dM = D. \n",
    "    Скрытый слой содержит H нейронов.\n",
    "    Выходной слой вычисляет оценки рейтигов для C классов.\n",
    "\n",
    "    Входы:\n",
    "     - x: тензор формы (N, d1, ..., dM),представляющий мини-блок\n",
    "       входных данных.\n",
    "     - params: список [w1, w2] тензоров, представляющих веса сети,\n",
    "       где w1 имеет форму (D, H), а w2 имеет форму (H, C).\n",
    "    \n",
    "     Возвращает:\n",
    "     - scores: тензор формы (N, C), представляющий оценки рейтингов \n",
    "       принадлежности классам входных данных x.  \n",
    "    \"\"\"\n",
    "    w1, w2 = params  # распаковка параметров\n",
    "    x = flatten(x)   # реформатируем x к форме (N, D)\n",
    "    h = tf.nn.relu(tf.matmul(x, w1)) # Скрытый слой : форма h - (N, H)\n",
    "    scores = tf.matmul(h, w2)        # Вычисление рейтингов, форма scores - (N, C)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_test():\n",
    "    # Вычислительный граф TensorFlow, по сути, является скрытой глобальной\n",
    "    # переменной. Чтобы избежать добавления к этой переменной графа по умолчанию при \n",
    "    # повторном запуске этой ячейки Jupyter notebook,\n",
    "    # очистим граф по умолчанию, прежде чем строить наш граф.\n",
    "    tf.reset_default_graph()\n",
    "    hidden_layer_size = 42\n",
    "\n",
    "    # Разместим наш код вычислительного графа в контексте менежджера tf.device,\n",
    "    # что позволит указывать TensorFlow, где должны размещаться тензоры.\n",
    "    with tf.device(device):\n",
    "        # Определяем  placehoder для входного тензора и тензоры для сетевых весов.\n",
    "        # Здесь мы объявляем w1 и w2, используя tf.zeros вместо tf.placeholder, \n",
    "        # Это означает, что значения w1 и w2 будут сохранены в самом вычислительном\n",
    "        # графе и тем самым будут сохраняться между прогонами графа; в\n",
    "        # частности, это означает, что нам не нужно передавать значения w1 и w2\n",
    "        # с использованием feed_dict, когда мы в конечном счете исполняем граф.\n",
    "        x = tf.placeholder(tf.float32)\n",
    "        w1 = tf.zeros((32 * 32 * 3, hidden_layer_size))\n",
    "        w2 = tf.zeros((hidden_layer_size, 10))\n",
    "        \n",
    "        # Вызываем функцию two_layer_fc, чтобы создать вычислительный\n",
    "        # граф для прямого прохода по сети.\n",
    "        scores = two_layer_fc(x, [w1, w2])\n",
    "    \n",
    "    # Используем  numpy для подготовки данных, которые ниже будут переданы\n",
    "    # вычислительный граф, путем  связи с x placeholder.\n",
    "    x_np = np.zeros((64, 32, 32, 3))\n",
    "    with tf.Session() as sess:\n",
    "        # Вызовы tf.zeros выше фактически не создают значения\n",
    "        # для w1 и w2;строка ниже заставляет TensorFlow создать экземпляры\n",
    "        # значений всех тензоров (например, w1 и w2), которые хранятся в графе.\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Здесь мы фактически выполняем граф, используя feed_dict, чтобы передать\n",
    "        # значение x_np и  привязать его  к заполнителю x;  TensorFlow вычисляет\n",
    "        # значение тензора scores, которое возвращается в виде numpy массива.\n",
    "        scores_np = sess.run(scores, feed_dict={x: x_np})\n",
    "        print(scores_np.shape)\n",
    "\n",
    "two_layer_fc_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый TensorFlow: Трехслойная  ConvNet\n",
    "\n",
    "Реализуйте функцию `three_layer_convnet`, которая будет выполнять прямое распространение для трехслойной сверточной сети. Сеть  должна иметь следующую архитектуру:\n",
    "\n",
    "1. Сверточный слой (со смещением) с фильтрами `channel_1`, каждый размером ` KW1 x KH1` и дополнением двумя нулями, P=2\n",
    "2. Нелинейность ReLU\n",
    "3. Сверточный слой (со смещением) с фильтрами `channel_2`, каждый размером ` KW2 x KH2` и  дополнением одним нулем, P=1\n",
    "4. Нелинейность ReLU\n",
    "5. Полносвязанный слой со смещением, вычисляющий оценки рейтингов для `C` классов .\n",
    "\n",
    "\n",
    "**СОВЕТ**: Для сверток: https://www.tensorflow.org/api_docs/python/tf/nn/conv2d; будьте внимательны с добавлением нулей!\n",
    "\n",
    "**СОВЕТ**: ДЛя смещений: https://www.tensorflow.org/performance/xla/broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_layer_convnet(x, params):\n",
    "    \"\"\"\n",
    "    Трехслойная сверточная сеть с описанной выше архитектурой.\n",
    "    \n",
    "    Входы:\n",
    "    - x: тензор формы (N, H, W, 3), представляющий мини-блок изображений\n",
    "    - params: список тензоров, представляющих веса и смещения \n",
    "      сети; должен содержать следующее:\n",
    "      - conv_w1: тензор формы (KH1, KW1, 3, channel_1) -\n",
    "        веса первого сверточного слоя.\n",
    "      - conv_b1: тензор формы (channel_1,) - смещения\n",
    "        первого сверточного слоя.\n",
    "      - conv_w2: тензор формы (KH2, KW2, channel_1, channel_2)\n",
    "        весовые коэффициенты второго сверточного слоя\n",
    "      - conv_b2: тензор  формы (channel_2,) - смещения\n",
    "        второго сверточного слоя.\n",
    "      - fc_w: тензор представляющий весовые коэффициенты полносвязанного слоя.\n",
    "        Укажите сами, какова должна быть форма?\n",
    "      - fc_b: тензор смещений полносвязанного слоя.\n",
    "        Укажите сами, какова должна быть форма?    \n",
    "    \"\"\"\n",
    "    conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b = params\n",
    "    scores = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Реализуйте прямое распространение для 3-х слойной ConvNet.      #\n",
    "    ############################################################################\n",
    "    x_padded = tf.pad(x,[[0,0],[2,2],[2,2],[0,0]],'CONSTANT')\n",
    "    conv1 = tf.nn.conv2d(x_padded,conv_w1,[1,1,1,1],padding='VALID')+conv_b1\n",
    "    relu1 = tf.nn.relu(conv1)\n",
    "    x_padded_1 = tf.pad(relu1,[[0,0],[1,1],[1,1],[0,0]],'CONSTANT')\n",
    "    conv2 = tf.nn.conv2d(x_padded_1,conv_w2,[1,1,1,1],padding='VALID')+conv_b2\n",
    "    relu2 = tf.nn.relu(conv2)\n",
    "    fc_x = flatten(relu2)\n",
    "    h = tf.matmul(fc_x, fc_w) + fc_b\n",
    "    scores = h\n",
    "    ############################################################################\n",
    "    #                              КОНЕЦ ВАШЕГО КОДА                           #\n",
    "    ############################################################################\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После определения  трехслойной ConvNet выше, запустите следующую ячейку, чтобы проверить вашу реализацию. Подобно двухслойной сети, используйте функцию `three_layer_convnet` для создания вычислительного графа, а затем исполните граф на блоке из нулей только для того, чтобы убедиться, что функция не дает сбоя, и создает выходы правильной формы (размерности).\n",
    "\n",
    "Когда вы запустите эту функцию, `scores_np` должен будет иметь форму` (64, 10) `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores_np has shape:  (64, 10)\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_test():\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    with tf.device(device):\n",
    "        x = tf.placeholder(tf.float32)\n",
    "        conv_w1 = tf.zeros((5, 5, 3, 6))\n",
    "        conv_b1 = tf.zeros((6,))\n",
    "        conv_w2 = tf.zeros((3, 3, 6, 9))\n",
    "        conv_b2 = tf.zeros((9,))\n",
    "        fc_w = tf.zeros((32 * 32 * 9, 10))\n",
    "        fc_b = tf.zeros((10,))\n",
    "        params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "        scores = three_layer_convnet(x, params)\n",
    "\n",
    "    # Входы  сверточных слоев представляют собой 4-мерные массивы с формой\n",
    "    # [размер_блока, высота, ширина, каналы]\n",
    "    x_np = np.zeros((64, 32, 32, 3))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        scores_np = sess.run(scores, feed_dict={x: x_np})\n",
    "        print('scores_np has shape: ', scores_np.shape)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    three_layer_convnet_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый TensorFlow: Этап обучения\n",
    "Теперь определим функцию `training_step`, которая создает часть вычислительного графика,  выполняющую  шаг обучения. Это потребует трех основных действий:\n",
    "\n",
    "1. Вычислить функцию потери\n",
    "2. Вычислить градиент функции потерь по всем весам\n",
    "3. Выполнить шаг обновления веса, используя (стохастический) градиентный спуск.\n",
    "\n",
    "Обратите внимание, что шаг обновления весов сам по себе является операцией в вычислительном графе - вызовы `tf.assign_sub` в` training_step` возвращают операции TensorFlow, которые изменяют веса при их выполнении. Здесь есть тонкость - когда мы называем `sess.run`, TensorFlow не выполняет все операции в вычислительном графе; он выполняет только минимальное подмножество графа, необходимое для вычисления выходов, которые мы запрашиваем. В результате наивное вычисление потерь не приводит к выполнению операций по обновлению веса, поскольку операции, необходимые для вычисления потерь, не зависят от результата обновления весов. Чтобы решить эту проблему, мы вставляем **зависимости управления** `tf.control_dependencies` в граф, добавляя дублирующий узел «loss» к графу, который зависит от выходов операций обновления веса; это объект, который мы фактически возвращаем из функции `training_step`. В результате, попросив TensorFlow оценить значение `loss`, возвращаемое ` training_step`, также будут неявно обновляться веса сети на мини-блоке данных.\n",
    "\n",
    "\n",
    "Нам нужно использовать несколько новых функций TensorFlow, чтобы сделать все это:\n",
    "- Для вычисления потерь в виде кросс-энтропии мы будем использовать\n",
    "`tf.nn.sparse_softmax_cross_entropy_with_logits`: https://www.tensorflow.org/api_docs/python/tf/nn/sparse_softmax_cross_entropy_with_logits\n",
    "- Для усреднения потерь на миниблоке данных мы будем использовать `tf.reduce_mean`:\n",
    "https://www.tensorflow.org/api_docs/python/tf/reduce_mean\n",
    "- Для вычисления градиентов потерь по отношению к весам мы будем использовать `tf.gradients`:https://www.tensorflow.org/api_docs/python/tf/gradients\n",
    "- для изменения значений весов, хранящихся в тензоре будем использовать`tf.assign_sub`:\n",
    "https://www.tensorflow.org/api_docs/python/tf/assign_sub\n",
    "- добавим зависимости управления к графу с помощью `tf.control_dependencies`:\n",
    "https://www.tensorflow.org/api_docs/python/tf/control_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(scores, y, params, learning_rate):\n",
    "    \"\"\"\n",
    "    Определяет часть вычислительного графа для шага обучения.\n",
    "\n",
    "     Входы:\n",
    "     - scores: тензор формы (N, C), содержащий классификационные рейтинги.\n",
    "     - y: тензор формы (N,), содержащий корректные метки классов;\n",
    "       y [i] == c означает, что c является правильным классом для scores[i].\n",
    "     - params: cписок тензоров,представляющих весовые коэффициенты модели\n",
    "     - learning_rate: скаляр , представляющий скорость обучения SGD\n",
    "      \n",
    "      \n",
    "     Возвращает:\n",
    "     - loss:  тензор формы () (скаляр)- потери на мини-блоке данных;\n",
    "       оценка потерь также выполняет шаг алгоритма SGD (см. выше).  \n",
    "    \"\"\"\n",
    "    # Сначала вычислим потери; первая строка дает потери для каждого примера в\n",
    "    # мини-блоке, вторая усредняет потери \n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "    loss = tf.reduce_mean(losses)\n",
    "\n",
    "    # Вычисляем градиент потерь по каждому параметру\n",
    "    # сети. Это некий магический вызов функции: TensorFlow внутренне\n",
    "    # обходит вычислительный граф, начиная с потерь в обратном направлении к каждому \n",
    "    # параметру и использует backpropagation, чтобы выяснить, как вычислять градиенты;\n",
    "    # Затем он добавляет новые операции в вычислительный граф, которые вычисляют\n",
    "    # запрошенные градиенты и возвращает список тензоров, которые будут\n",
    "    # содержать запрошенные градиенты при выполнении.\n",
    "    grad_params = tf.gradients(loss, params)\n",
    "    \n",
    "    \n",
    "    # Реализуем шаг градиентного спуска по всем параметрам модели.\n",
    "    new_weights = []   \n",
    "    for w, grad_w in zip(params, grad_params):\n",
    "        new_w = tf.assign_sub(w, learning_rate * grad_w)\n",
    "        new_weights.append(new_w)\n",
    "\n",
    "    # Вставляем управляющую зависимость, чтобы оценка потерь приводила\n",
    "    # к обновлению веса; см. обсуждение выше.\n",
    "    \n",
    "    with tf.control_dependencies(new_weights):\n",
    "        return tf.identity(loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый TensorFlow: цикл обучения\n",
    "Теперь мы реализуем цикл обучения, используя операции низкого уровня TensorFlow. Будем обучать модель, используя простой стохастический градиентный спуск. Функция «training_step» определила часть вычислительного графа, который связан с этапом обучения, а функция «train_part2» выполняет итерации по обучающим данным, осуществляя  шаги обучения на каждом мини-блоке и периодически оценивает точность на валидационном множестве.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part2(model_fn, init_fn, learning_rate):\n",
    "    \"\"\"\n",
    "    \n",
    "    Входы:\n",
    "     - model_fn: функция Python, которая выполняет прямое распространение,\n",
    "       используя TensorFlow; она должна иметь следующую сигнатуру:\n",
    "       scores = model_fn (x, params), где x - тензор, представляющий\n",
    "       мини-блок данныхс изображениями, params - список тензоров, хранящих\n",
    "       веса модели, scores - тензор  формы (N, C), содержащий\n",
    "       рейтинги  всех элементов x.\n",
    "     - init_fn: функция Python, которая инициализирует параметры модели.\n",
    "       Она должна иметь сигнатуру params = init_fn (), где params - это список\n",
    "       тензоров, хранящих (случайно инициализированные) веса\n",
    "       модели.\n",
    "     - learning_rate: вещественное значение Python, представлящее скорость обучения  SGD.\n",
    "      \n",
    "    \"\"\"\n",
    "    # Очистка графа по умолчанию\n",
    "    tf.reset_default_graph()\n",
    "    is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "    # Формирование вычислительного графа для прямого и обратного распространения,\n",
    "    # и обновления весов.\n",
    "    with tf.device(device):\n",
    "        # Создание плейсхолдеров для данных и меток\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "        params = init_fn()           # Инициализация параметров модели\n",
    "        scores = model_fn(x, params) # Прямое распространение\n",
    "        loss = training_step(scores, y, params, learning_rate)\n",
    "\n",
    "    # Дествительное многократное исполнение графа на обучающих данных \n",
    "    with tf.Session() as sess:\n",
    "        # Инициализация переменных, которые размещаются в самом графе\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for t, (x_np, y_np) in enumerate(train_dset):\n",
    "            # Исполнение графа на блоке обучающих данных; вызов заставляет\n",
    "            # TensorFlow оценивать потери loss, что приводит к успешному шагу SGD\n",
    "            feed_dict = {x: x_np, y: y_np}\n",
    "            loss_np = sess.run(loss, feed_dict=feed_dict)\n",
    "            \n",
    "            \n",
    "            # Периодически выводим потери и проверяем точность на валидационном множестве\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                check_accuracy(sess, val_dset, x, scores, is_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый TensorFlow: проверка точности \n",
    "При обучении модели мы будем использовать следующую функцию для проверки точности нашей модели на обучающем и валидационном множестве данных. Обратите внимание, что эта функция принимает объект Session как один из  аргументов; это необходимо, так как функция должна фактически запускать  исполнение вычислительного графа много раз на данных, которые она загружает из набора данных `dset`.\n",
    "\n",
    "Также обратите внимание, что мы повторно используем один и тот же вычислительный граф как для обучения, так и для оценивания модели; однако, поскольку функция `check_accuracy` никогда не вычисляет значение` loss` в вычислительном графе, часть графа, которая обновляет веса, не выполняется на валидационном множестве.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(sess, dset, x, scores, is_training=None):\n",
    "    \"\"\"\n",
    "    Проверяет точность классификации.\n",
    "    \n",
    "     Входы:\n",
    "     - sess: сеанс, который будет использоваться для запуска графа\n",
    "     - dset: объект Dataset, используемый для проверки точности\n",
    "     - x: тензор плейсхолдер, представляющий входные изображения\n",
    "     - scores: тензор, представляющий рейтинги классов на выходе модели;\n",
    "     это тензор, который мы просим TensorFlow оценить.\n",
    "      \n",
    "     Возвращает: ничего не возвращает, но печатает точность модели\n",
    "    \"\"\"\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for x_batch, y_batch in dset:\n",
    "        feed_dict = {x: x_batch, is_training: 0}\n",
    "        scores_np = sess.run(scores, feed_dict=feed_dict)\n",
    "        y_pred = scores_np.argmax(axis=1)\n",
    "        num_samples += x_batch.shape[0]\n",
    "        num_correct += (y_pred == y_batch).sum()\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f%%)' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый TensorFlow: инициализация\n",
    "Мы будем использовать следующую утилиту для инициализации матриц весов моделей, использующую метод\n",
    "нормировки Кайминга (Хе).\n",
    "\n",
    "[1] He et al, *Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\n",
    "*, ICCV 2015, https://arxiv.org/abs/1502.01852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaiming_normal(shape):\n",
    "    if len(shape) == 2:\n",
    "        fan_in, fan_out = shape[0], shape[1]\n",
    "    elif len(shape) == 4:\n",
    "        fan_in, fan_out = np.prod(shape[:3]), shape[3]\n",
    "    return tf.random_normal(shape) * np.sqrt(2.0 / fan_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый  TensorFlow: обучение 2-х слойной нейросети\n",
    "Наконец, мы готовы использовать все части, определенные выше, для обучения двухслойной полносвязной сети на множестве данных CIFAR-10.\n",
    "\n",
    "Нам просто нужно определить функцию для инициализации весов модели и вызвать `train_part2`.\n",
    "\n",
    "Определение весов сети представляет собой еще один важный компонент TensorFlow API: `tf.Variable`. TensorFlow Variable - это тензор-переменная, значение которой хранится в графе и сохраняется на разных  циклах исполнения вычислительного графа; однако в отличие от констант, определенных с помощью `tf.zeros` или` tf.random_normal`, значения переменной могут быть изменены при выполнении графа; эти изменения будут сохраняться в графе. Обучаемые параметры сети обычно хранятся в переменных.\n",
    "\n",
    "Вам не нужно настраивать гиперпараметры, но вы должны достичь точности выше 40% после одной эпохи обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.2846\n",
      "Got 131 / 1000 correct (13.10%)\n",
      "Iteration 100, loss = 1.9373\n",
      "Got 373 / 1000 correct (37.30%)\n",
      "Iteration 200, loss = 1.5112\n",
      "Got 378 / 1000 correct (37.80%)\n",
      "Iteration 300, loss = 1.8303\n",
      "Got 360 / 1000 correct (36.00%)\n",
      "Iteration 400, loss = 1.8335\n",
      "Got 415 / 1000 correct (41.50%)\n",
      "Iteration 500, loss = 1.8088\n",
      "Got 425 / 1000 correct (42.50%)\n",
      "Iteration 600, loss = 1.7331\n",
      "Got 424 / 1000 correct (42.40%)\n",
      "Iteration 700, loss = 1.9773\n",
      "Got 448 / 1000 correct (44.80%)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_init():\n",
    "    \"\"\"\n",
    "    Инициализирует веса двухслойной сети для использования с\n",
    "    two_layer_network, определенной выше.\n",
    "    \n",
    "     Входы: отсутствуют\n",
    "    \n",
    "     Возвращает: список:\n",
    "     - w1: переменная TensorFlow, представляющая веса первого слоя\n",
    "     - w2: переменная TensorFlow, представляющая веса второго слоя\n",
    "    \"\"\"\n",
    "    hidden_layer_size = 4000\n",
    "    w1 = tf.Variable(kaiming_normal((3 * 32 * 32, 4000)))\n",
    "    w2 = tf.Variable(kaiming_normal((4000, 10)))\n",
    "    return [w1, w2]\n",
    "\n",
    "learning_rate = 1e-2\n",
    "train_part2(two_layer_fc, two_layer_fc_init, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовый  TensorFlow: Обучение 3-х слойной  ConvNet\n",
    "\n",
    "Теперь мы будем использовать TensorFlow для обучения трехслойной ConvNet на CIFAR-10.\n",
    "\n",
    "Вам нужно реализовать функцию `three_layer_convnet_init`. Напомним архитектуру сети:\n",
    "\n",
    "1. Сверточный слой (со смещением) с 32 фильтрами 5 × 5 с дополнением нулями Р=2\n",
    "2. ReLU\n",
    "3. Сверточный слой (со смещением) с 16 фильтрами 3x3 с дополнением нулями Р=1\n",
    "4. ReLU\n",
    "5. Полносвязный слой (со смещением) для вычисления оценок scores 10 классов\n",
    "\n",
    "Вам не нужно делать какие-либо настройки гиперпараметров, но вы должны получить точность выше 43% после одной эпохи обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 3.5616\n",
      "Got 77 / 1000 correct (7.70%)\n",
      "Iteration 100, loss = 1.9414\n",
      "Got 352 / 1000 correct (35.20%)\n",
      "Iteration 200, loss = 1.5771\n",
      "Got 390 / 1000 correct (39.00%)\n",
      "Iteration 300, loss = 1.7180\n",
      "Got 387 / 1000 correct (38.70%)\n",
      "Iteration 400, loss = 1.7665\n",
      "Got 433 / 1000 correct (43.30%)\n",
      "Iteration 500, loss = 1.7898\n",
      "Got 439 / 1000 correct (43.90%)\n",
      "Iteration 600, loss = 1.6822\n",
      "Got 462 / 1000 correct (46.20%)\n",
      "Iteration 700, loss = 1.6048\n",
      "Got 453 / 1000 correct (45.30%)\n"
     ]
    }
   ],
   "source": [
    "def three_layer_convnet_init():\n",
    "    \"\"\"\n",
    "    Инициализирует веса трехслойной ConvNet, для использования с\n",
    "    three_layer_convnet, определенной выше.\n",
    "    \n",
    "     Входы: Отсутствуют\n",
    "    \n",
    "     Возвращает список, содержащий:\n",
    "     - conv_w1: TensorFlow переменная, содержащая веса для первого слоя conv\n",
    "     - conv_b1: переменная TensorFlow, содержащая смещения для первого слоя conv\n",
    "     - conv_w2: TensorFlow Переменная, содержащая веса для второго слоя conv\n",
    "     - conv_b2: переменная TensorFlow, содержащая смещения для второго слоя conv\n",
    "     - fc_w: TensorFlow Переменная, содержащая веса  для полносвязанного слоя\n",
    "     - fc_b: переменная TensorFlow, содержащая смещения для полносвязанного слоя\n",
    "    \"\"\"\n",
    "    params = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Инициализаровать параметры 3-х слойной сети                     #\n",
    "    ############################################################################\n",
    "    conv_w1 = tf.Variable(kaiming_normal((5, 5, 3, 32)))\n",
    "    conv_b1 = tf.Variable(tf.zeros((32,)))\n",
    "    conv_w2 = tf.Variable(kaiming_normal((3, 3, 32, 16)))\n",
    "    conv_b2 = tf.Variable(tf.zeros((16,)))\n",
    "    fc_w = tf.Variable(kaiming_normal((32 * 32 * 16, 10)))\n",
    "    fc_b = tf.Variable(tf.zeros((10,)))\n",
    "    params = [conv_w1, conv_b1, conv_w2, conv_b2, fc_w, fc_b]\n",
    "    ############################################################################\n",
    "    #                             КОНЕЦ ВАШЕГО КОДА                            #\n",
    "    ############################################################################\n",
    "    return params\n",
    "\n",
    "learning_rate = 3e-3\n",
    "train_part2(three_layer_convnet, three_layer_convnet_init, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть III: Keras модель API\n",
    "Реализация нейронной сети с использованием базового API TensorFlow - это хороший способ понять, как работает TensorFlow, но несколько не удобно - нам пришлось вручную отслеживать все тензоры, у которых есть обучаемые параметры, и нам пришлось использовать зависимости управления для реализации шага обновления алгоритма SGD. Это не сложно для небольшой сети, но усложняется при большой модели нейросети.\n",
    "\n",
    "К счастью, TensorFlow предоставляет пакеты более высокого уровня, такие как `tf.keras` и` tf.layers`, которые упрощают создание моделей из модульных объектно-ориентированных слоев; `tf.train` позволяет легко обучать эти модели с помощью различных алгоритмов оптимизации.\n",
    "\n",
    "В этой части блокнота мы определим модели нейронных сетей, используя API интерфейс высокого уровня `tf.keras.Model`. Чтобы реализовать свою собственную модель, вам необходимо сделать следующее:\n",
    "\n",
    "1. Определите новый класс, который является подклассом `tf.keras.model`. Присвойте вашему классу соответсвующее имя, которое указывает его назначение, например «TwoLayerFC» или «ThreeLayerConvNet».\n",
    "2. В инициализаторе `__init __ ()` нового класса определите все слои, которые вам нужны в качестве атрибутов класса. Пакет `tf.layers` предоставляет множество обобщенных нейросетевых слоёв, таких как` tf.layers.Dense` для полносвязанных слоев и `tf.layers.Conv2D` для сверточных слоев. Внутри эти слои будут создавать тензоры «Variable» для любых обучаемых параметров. **Предупреждение**: Не забудьте вызвать `super () .__ init __ ()` в качестве первой строки вашего инициализатора!\n",
    "3. Реализуйте метод `call ()` для вашего класса; он осуществляет прямое распространение для вашей модели и определяет *связи*  вашей сети. Слои, определенные в `__init __ ()`, применяются в  `__call __ ()`, поэтому они могут использоваться как объекты функций, которые преобразуют входные тензоры в выходные тензоры. Не определяйте новые слои в `call ()`; любые слои, которые вы хотите использовать при прямом распространении, должны быть определены в `__init __ ()`.\n",
    "\n",
    "После того, как вы определили свой подкласс `tf.keras.Model`, вы можете создать его экземпляр и использовать его подобно модели из части II.\n",
    "\n",
    "\n",
    "### Модуль прикладного интерфейса (API): 2-х слойная сеть\n",
    "\n",
    "Вот конкретный пример использования API `tf.keras.Model` для определения двухслойной сети. \n",
    "\n",
    "Мы используем объект `Initializer` для задания начальных значений обучаемых параметров слоев; в частности, `tf.variance_scaling_initializer` соответствует методу инициализации Kaiming (Хе), использованному в части II. Подробнее об этом можно узнать здесь: https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer\n",
    "\n",
    "Объект `tf.layers.Dense` используется для представления двух полносвязанных слоев модели. В дополнение к умножению входа на весовую матрицу и добавлению вектора смещения, этот слой также может обеспечить применение нелинейности. Для первого слоя ниже используется функция активации ReLU, для этого конструктору передается параметр `activation = tf.nn.relu`; во втором слое нелиненйость не применяется.\n",
    "\n",
    "К сожалению, функция `flatten`, определенная в части II, несовместима с API` tf.keras.Model`; к счастью, мы можем использовать `tf.layers.flatten` для выполнения той же операции. Проблема с нашей функцией «уплощения» из части II связана со статическими или динамическими формами для тензоров, что выходит за рамки этого блокнота; вы можете больше узнать о различии [в документации] (https://www.tensorflow.org/programmers_guide/faq#tensor_shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super().__init__()        \n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.fc1 = tf.layers.Dense(hidden_size, activation=tf.nn.relu,\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.layers.Dense(num_classes,\n",
    "                                   kernel_initializer=initializer)\n",
    "    def call(self, x, training=None):\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\"Небольшой  тест для проверки модели TwoLayerFC выше\"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "\n",
    "    # Как обычно, в TensorFlow сначала нужно определить вычислительный граф.\n",
    "    # С этой целью мы сначала создадим объект TwoLayerFC, а затем используем \n",
    "    # его для получения scores.\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, input_size))\n",
    "        scores = model(x)\n",
    "\n",
    "    # Теперь, когда наш вычислительный граф определен, мы можем выполнить вычисления на графе\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        scores_np = sess.run(scores)\n",
    "        print(scores_np.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Функциональный  API: 2-х слойная нейронная сеть\n",
    "Пакет `tf.layers` предоставляет два разных API  высокого уровня для определения моделей нейронных сетей. В приведенном выше примере мы использовали **объектно-ориентированный API**, где каждый слой нейронной сети представлен как объект Python (например, `tf.layers.Dense`). Здесь мы рассмотрим функциональный API, где каждый уровень представляет собой функцию Python (например, `tf.layers.dense`), входы и выходы которой являются тензорами TensorFlow и которая внутри использует тензоры в вычислительном графе для хранения любых обучаемых весов.\n",
    "\n",
    "Чтобы построить сеть, нужно передать входной тензор на первый слой и последовательно построить последующие слои. Вот пример того, как построить ту же двухслойную сеть с функциональным API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(inputs, hidden_size, num_classes):     \n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    flattened_inputs = tf.layers.flatten(inputs)\n",
    "    fc1_output = tf.layers.dense(flattened_inputs, hidden_size, activation=tf.nn.relu,\n",
    "                                 kernel_initializer=initializer)\n",
    "    scores = tf.layers.dense(fc1_output, num_classes,\n",
    "                             kernel_initializer=initializer)\n",
    "    return scores\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\"Небольшой  тест для проверки модели TwoLayerFC выше\"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "\n",
    "    \n",
    "    # Как обычно, в TensorFlow сначала нужно определить вычислительный граф.\n",
    "    # Для этого мы сначала построим двухслойный сетевой граф, вызвав\n",
    "    # two_layer_network (). Эта функция строит вычислительный граф\n",
    "    # и возвращает тензор рейтингов scores.\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, input_size))\n",
    "        scores = two_layer_fc_functional(x, hidden_size, num_classes)\n",
    "\n",
    "    # Теперь, когда наш вычислительный граф определен, мы можем выполнить вычисления на графе\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        scores_np = sess.run(scores)\n",
    "        print(scores_np.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras модель  API: 3-х слойная сеть  ConvNet\n",
    "Теперь настало время реализовать трехслойную ConvNet с использованием API `tf.keras.Model`. Модель должна иметь ту же архитектуру, что и ранее в части II:\n",
    "\n",
    "1. Сверточный слой с 5 х 5 фильтрами и  с дополнением нулями Р=2\n",
    "2. Нелинейность ReLU\n",
    "3. Сверточный слой с 3 x 3 фильтрами и  с дополнением нулями Р=1\n",
    "4. Нелинейность ReLU\n",
    "5. Полносвязный слой, формирующий рейтинги  классов scores\n",
    "\n",
    "Вы должны инициализировать веса сети, используя тот же метод инициализации, который использовался в двухслойной сети выше.\n",
    "\n",
    "**Совет**: обратитесь к документации для `tf.layers.Conv2D` и` tf.layers.Dense`:\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # ЗАДАНИЕ:                                                             #\n",
    "        # Реализуйте метод __init__ для трехслойной ConvNet. Вы должys создать #\n",
    "        # объекты слоя, которые будут использоваться при прямом распространении#\n",
    "        ########################################################################\n",
    "        initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "        self.conv1 = tf.layers.Conv2D(channel_1,[5,5],[1,1],padding='same',activation=tf.nn.relu,\n",
    "                                      kernel_initializer=initializer)\n",
    "        self.conv2 = tf.layers.Conv2D(channel_2,[3,3],[1,1],padding='same',activation=tf.nn.relu,\n",
    "                                      kernel_initializer=initializer)\n",
    "        self.fc = tf.layers.Dense(num_classes,kernel_initializer=initializer)\n",
    "        ########################################################################\n",
    "        #                           КОНЕЦ ВАШЕГО КОДА                          #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=None):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # ЗАДАНИЕ: выполнить прямое распространение для 3-х слойной ConvNet.   #\n",
    "        # Используйте объекты слоя, определенные в методе __init__.            #\n",
    "        ########################################################################\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = tf.layers.flatten(x)\n",
    "        scores = self.fc(x)\n",
    "        ########################################################################\n",
    "        #                          КОНЕЦ ВАШЕГО КОДА                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После завершения реализации «ThreeLayerConvNet» выше вы можете запустить код ниже, чтобы убедиться, что ваша реализация не сбоит и возвращает выходы ожидаемой формы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        scores_np = sess.run(scores)\n",
    "        print(scores_np.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras модель API: цикл обучения\n",
    "Нам нужно реализовать несколько иной цикл обучения, когда используем API `tf.keras.Model`. Вместо того, чтобы вычислять градиенты и обновлять веса вручную, будем использовать объект `Optimizer` из пакета` tf.train`, который позаботится об всех деталях. Вы можете узнать больше об `Optimizer` здесь:\n",
    "https://www.tensorflow.org/api_docs/python/tf/train/Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1):\n",
    "    \"\"\"\n",
    "    \n",
    "    Простой цикл обучения для использования с моделями, определенными с помощью tf.keras. \n",
    "    Он обучает модель на одной эпохе на мн-ве CIFAR-10 и периодически проверяет\n",
    "    точность на валидационном мн-ве CIFAR-10.\n",
    "    \n",
    "     Входы:\n",
    "     - model_init_fn: функция, которая не принимает никаких параметров; когда её вызывают\n",
    "       создает модель, которую мы хотим обучить: model = model_init_fn ()\n",
    "     - optimizer_init_fn: функция, которая не принимает никаких параметров; когда его вызывают\n",
    "       создает объект Optimizer, который мы будем использовать для оптимизации модели:\n",
    "       optimizer = optimizer_init_fn ()\n",
    "     - num_epochs: количество эпох обучения\n",
    "    \n",
    "     Возвращает: ничего не возвращает, но выводит ход обучения\n",
    "      \n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()    \n",
    "    with tf.device(device):\n",
    "        # Cтроим вычислительный граф, который будем использовать для обучения модели. \n",
    "        # Используем model_init_fn для создания модели, объявляем плейсхолдеры для\n",
    "        # данных и меток\n",
    "        x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        y = tf.placeholder(tf.int32, [None])\n",
    "                \n",
    "        # Нам нужен особый плейсхолдер, чтобы явно указать, находится ли модель в фазе обучения\n",
    "        # или нет. Это связано с тем, что ряд слоев ведет себя по-разному в\n",
    "        # ходе обучения и в ходе тестирования, например, dropout и блочная нормализация.\n",
    "        # Мы передаем эту переменную в граф через feed_dict, как показано ниже.\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "                \n",
    "        # Используем  модель, чтобы сделать прямое распространение\n",
    "        scores = model_init_fn(x, is_training)\n",
    "\n",
    "        # Вычисляем потери\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=scores)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        # Используем optimizer_fn для создания объекта Optimizer, затем используем его\n",
    "        # для настроики этапа обучения. Попросим TensorFlow оценить\n",
    "        # train_op, возвращаемый optimizer.minimize(loss), что заставит сделать\n",
    "        # один шаг обновления, используя текущий мини-блок данных.\n",
    "        \n",
    "        # Обратите внимание, что мы используем tf.control_dependencies, чтобы заставить модель\n",
    "        # запускать tf.GraphKeys.UPDATE_OPS на каждом шаге обучения. tf.GraphKeys.UPDATE_OPS\n",
    "        # содержит операторы, которые обновляют состояния сети.\n",
    "        # Например, функция tf.layers.batch_normalization добавляет операторы \n",
    "        # обновления текущего среднего и дисперсии для tf.GraphKeys.UPDATE_OPS.\n",
    "        \n",
    "        optimizer = optimizer_init_fn()\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss)\n",
    "\n",
    "    # Теперь мы можем много раз запускать вычислительный граф для обучения модели.\n",
    "    # Когда мы вызываем sess.run, мы просим оценить train_op, что приводит\n",
    "    # к обновлению парметров модели.\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            print('Starting epoch %d' % epoch)\n",
    "            for x_np, y_np in train_dset:\n",
    "                feed_dict = {x: x_np, y: y_np, is_training:1}\n",
    "                loss_np, _ = sess.run([loss, train_op], feed_dict=feed_dict)\n",
    "                if t % print_every == 0:\n",
    "                    print('Iteration %d, loss = %.4f' % (t, loss_np))\n",
    "                    check_accuracy(sess, val_dset, x, scores, is_training=is_training)\n",
    "                    print()\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras модель API: обучение 2-х слойной нейросети\n",
    "\n",
    "Теперь мы можем использовать инструменты, определенные выше, для обучения двухслойной сети на мн-ве данных CIFAR-10. Определим `model_init_fn` и` optimizer_init_fn`, которые создают модель и оптимизатор при вызове. Будем обучать модель с помощью простого стохастического градиентного спуска. Для этого определим функцию `tf.train.GradientDescentOptimizer`; вы можете\n",
    "[прочитать это здесь](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer).\n",
    "\n",
    "Вам не требуется  настраивать гиперпараметры, но вы должны достичь точности выше 40% после одной эпохи обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 2.9074\n",
      "Got 119 / 1000 correct (11.90%)\n",
      "\n",
      "Iteration 100, loss = 1.8721\n",
      "Got 366 / 1000 correct (36.60%)\n",
      "\n",
      "Iteration 200, loss = 1.4586\n",
      "Got 389 / 1000 correct (38.90%)\n",
      "\n",
      "Iteration 300, loss = 1.7800\n",
      "Got 341 / 1000 correct (34.10%)\n",
      "\n",
      "Iteration 400, loss = 1.8933\n",
      "Got 419 / 1000 correct (41.90%)\n",
      "\n",
      "Iteration 500, loss = 1.7896\n",
      "Got 427 / 1000 correct (42.70%)\n",
      "\n",
      "Iteration 600, loss = 1.8617\n",
      "Got 432 / 1000 correct (43.20%)\n",
      "\n",
      "Iteration 700, loss = 1.8906\n",
      "Got 429 / 1000 correct (42.90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    return TwoLayerFC(hidden_size, num_classes)(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras модель API: обучениие 2-х слойной нейросети (функциональный API)\n",
    "Аналогичным образом обцчаем двухслойную сеть, построенную с использованием функционального API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 3.0776\n",
      "Got 100 / 1000 correct (10.00%)\n",
      "\n",
      "Iteration 100, loss = 1.8249\n",
      "Got 378 / 1000 correct (37.80%)\n",
      "\n",
      "Iteration 200, loss = 1.5358\n",
      "Got 404 / 1000 correct (40.40%)\n",
      "\n",
      "Iteration 300, loss = 1.8241\n",
      "Got 391 / 1000 correct (39.10%)\n",
      "\n",
      "Iteration 400, loss = 1.8732\n",
      "Got 416 / 1000 correct (41.60%)\n",
      "\n",
      "Iteration 500, loss = 1.7844\n",
      "Got 448 / 1000 correct (44.80%)\n",
      "\n",
      "Iteration 600, loss = 1.8352\n",
      "Got 441 / 1000 correct (44.10%)\n",
      "\n",
      "Iteration 700, loss = 1.9356\n",
      "Got 450 / 1000 correct (45.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    return two_layer_fc_functional(inputs, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras модель API: Обучение 3-х слойной сети ConvNet\n",
    "Здесь Вы должны использовать инструменты, которые определили выше, для обучения трехслойной ConvNet на множестве данных CIFAR-10. ConvNet должна использовать 32 фильтра в первом сверточном слое и 16 фильтров во втором слое.\n",
    "\n",
    "Для обучения модели вы должны использовать градиентный спуск с моментом Нестерова 0.9.\n",
    "\n",
    "**СОВЕТ**: https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer\n",
    "\n",
    "Вам не нужно выполнять выбор гиперпараметров, но Вы должны достичь точности выше 45% после обучения в течение одной эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 2.8935\n",
      "Got 78 / 1000 correct (7.80%)\n",
      "\n",
      "Iteration 100, loss = 1.7071\n",
      "Got 401 / 1000 correct (40.10%)\n",
      "\n",
      "Iteration 200, loss = 1.3405\n",
      "Got 478 / 1000 correct (47.80%)\n",
      "\n",
      "Iteration 300, loss = 1.4474\n",
      "Got 486 / 1000 correct (48.60%)\n",
      "\n",
      "Iteration 400, loss = 1.3130\n",
      "Got 502 / 1000 correct (50.20%)\n",
      "\n",
      "Iteration 500, loss = 1.4488\n",
      "Got 543 / 1000 correct (54.30%)\n",
      "\n",
      "Iteration 600, loss = 1.4090\n",
      "Got 543 / 1000 correct (54.30%)\n",
      "\n",
      "Iteration 700, loss = 1.3727\n",
      "Got 537 / 1000 correct (53.70%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Завершите реализацию model_fn.                                  #\n",
    "    ############################################################################\n",
    "    model = ThreeLayerConvNet(channel_1,channel_2,num_classes)\n",
    "    ############################################################################\n",
    "    #                           КОНЕЦ ВАШЕГО КОДА                              #\n",
    "    ############################################################################\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Завершите реализацию model_fn.                                  #\n",
    "    ############################################################################\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "    ############################################################################\n",
    "    #                           КОНЕЦ ВАШЕГО КОДА                              #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть IV:  последовательный API-интерфейс  Keras\n",
    "В третьей части мы ввели API-интерфейс `tf.keras.Model`, который позволяет определять модели с любым количеством обучаемых слоев и с произвольной связностью между слоями.\n",
    "\n",
    "Однако для многих моделей не нужна такая гибкость - многие модели могут быть выражены в виде последовательного стека слоев, причем выход одного слоя подается на следующего слоя в качестве входа. Если  модель соответствует этому шаблону, то существует простой способ определения модели с помощью `tf.keras.Sequential`. В этом случае не нужно писать какие-либо пользовательские классы; просто вызывается конструктор `tf.keras.Sequential` со списком, содержащим последовательность объектов слоя.\n",
    "\n",
    "Одна из сложностей использовния `tf.keras.Sequential` заключается то, что нужно определить форму входного тензора для модели, передав значение `input_shape` первого слоя модели.\n",
    "\n",
    "### Последовательный API-интерфейс Keras: 2-х слойная сеть\n",
    "Перепишем двухслойную полносвязанную сеть с помощью `tf.keras.Sequential` и обучим ее с использованием цикла обучения, определенного выше.\n",
    "\n",
    "Вам не нужно выполнять выбор гиперпараметров, но вы должны видеть точность выше 40% после обучения сети в течение одной эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 2.9806\n",
      "Got 107 / 1000 correct (10.70%)\n",
      "\n",
      "Iteration 100, loss = 2.0099\n",
      "Got 360 / 1000 correct (36.00%)\n",
      "\n",
      "Iteration 200, loss = 1.4026\n",
      "Got 390 / 1000 correct (39.00%)\n",
      "\n",
      "Iteration 300, loss = 1.7913\n",
      "Got 379 / 1000 correct (37.90%)\n",
      "\n",
      "Iteration 400, loss = 1.7431\n",
      "Got 422 / 1000 correct (42.20%)\n",
      "\n",
      "Iteration 500, loss = 1.7702\n",
      "Got 418 / 1000 correct (41.80%)\n",
      "\n",
      "Iteration 600, loss = 1.8627\n",
      "Got 429 / 1000 correct (42.90%)\n",
      "\n",
      "Iteration 700, loss = 2.0135\n",
      "Got 440 / 1000 correct (44.00%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn(inputs, is_training):\n",
    "    input_shape = (32, 32, 3)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "        tf.layers.Flatten(input_shape=input_shape),\n",
    "        tf.layers.Dense(hidden_layer_size, activation=tf.nn.relu,\n",
    "                        kernel_initializer=initializer),\n",
    "        tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model(inputs)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Последовательный API-интерфейс Keras: 3-х слойная сеть ConvNet\n",
    "Здесь вы должны использовать `tf.keras.Sequential` для переопределения одной и той же трехуровневой архитектуры ConvNet, используемой в Части II и Части III. Напоминаем, что ваша модель должна иметь следующую архитектуру:\n",
    "\n",
    "1. Сверточный слой с  16 фильтрами 5x5 с дополнением нулями Р=2\n",
    "2. Нелинейность ReLU\n",
    "3. Сверточный слой с 32 фильтрами 3x3 с дополнением нулями Р=1\n",
    "4. Нелинейность ReLU\n",
    "5. Полносвязный слой, оценивающий рейтинги классов scores\n",
    "\n",
    "Необходимо инициализировать весовые коэффициенты модели с помощью `tf.variance_scaling_initializer`, как указано выше.\n",
    "\n",
    "Модель необходимо обучить  с использованием момента Нестерова 0.9.\n",
    "\n",
    "Вам не нужно выполнять выбор гиперпараметров, но вы должны достичь точности выше 45% после обучения в течение одной эпохи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Iteration 0, loss = 2.8855\n",
      "Got 88 / 1000 correct (8.80%)\n",
      "\n",
      "Iteration 100, loss = 1.8661\n",
      "Got 357 / 1000 correct (35.70%)\n",
      "\n",
      "Iteration 200, loss = 1.5427\n",
      "Got 411 / 1000 correct (41.10%)\n",
      "\n",
      "Iteration 300, loss = 1.6745\n",
      "Got 435 / 1000 correct (43.50%)\n",
      "\n",
      "Iteration 400, loss = 1.5944\n",
      "Got 464 / 1000 correct (46.40%)\n",
      "\n",
      "Iteration 500, loss = 1.6358\n",
      "Got 492 / 1000 correct (49.20%)\n",
      "\n",
      "Iteration 600, loss = 1.6221\n",
      "Got 484 / 1000 correct (48.40%)\n",
      "\n",
      "Iteration 700, loss = 1.6127\n",
      "Got 498 / 1000 correct (49.80%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn(inputs, is_training):\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Создать 3-х слойную  ConvNet, испольуя tf.keras.Sequential.     #\n",
    "    ############################################################################\n",
    "    input_shape = (32, 32, 3)\n",
    "    channel_1, channel_2, num_classes = 32, 16, 10\n",
    "    initializer = tf.variance_scaling_initializer(scale=2.0)\n",
    "    layers = [\n",
    "         # 'Same' padding acts similar to zero padding of 2 for this input\n",
    "         tf.layers.Conv2D(channel_1,[5,5],strides=1, \\\n",
    "                                 padding=\"same\", activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = initializer,input_shape=(32, 32,3)),\n",
    "         tf.layers.Conv2D(channel_2,[3,3],strides=1, \\\n",
    "                                 padding=\"same\", activation=tf.nn.relu,\\\n",
    "                                 kernel_initializer = initializer),\n",
    "         tf.layers.Flatten(input_shape=input_shape),\n",
    "         tf.layers.Dense(num_classes, kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    ############################################################################\n",
    "    #                            КОНЕЦ ВАШЕГО КОДА                             #\n",
    "    ############################################################################\n",
    "    return model(inputs)\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # ЗАДАНИЕ: Завершить реализацию model_fn.                                  #\n",
    "    ############################################################################\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n",
    "    ############################################################################\n",
    "    #                           КОНЕЦ ВАШЕГО КОДА                              #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть V: CIFAR-10 - открытые проблемы\n",
    "\n",
    "В этом разделе вы можете поэкспериментировать с любой архитектурой ConvNet, которую вы хотели бы использовать на CIFAR-10.\n",
    "\n",
    "Вы должны поэкспериментировать с архитектурами, гиперпараметрами, функциями потерь, регуляризацией или чем-либо еще, что вы можете придумать для обучения модели, которая достигает **не менее 70%** точности на **валидационном** множестве в течение 10 эпох. Вы можете использовать функции `check_accuracy` и` train` определенные выше, или вы можете реализовать свой собственный цикл обучения.\n",
    "\n",
    "Опишите, что вы делали в конце этого блокнота.\n",
    "\n",
    "### С чем Вам следует экспериментировать:\n",
    "- **Размер фильтра**: Выше мы использовали 5x5 и 3x3; это оптимально?\n",
    "- **Количество фильтров**: Выше мы использовали 16 и 32 фильтра. Будет ли большее или меньшее число лучше?\n",
    "- **Пулинг**: Мы не использовали никакого пулинга выше. Будет ли пулинг улучшать модель?\n",
    "- **Нормализация**: улучшится ли ваша модель при использовании блочной нормализации, нормализации на слое, нормализации группы или какой-либо иной стратегии нормализации?\n",
    "- **Архитектура**: В приведенной выше ConvNet имеется только три уровня обучаемых параметров. Будет ли более глубокая модель работать лучше?\n",
    "- **Глобальный усредняющий пулинг**: вместо \"уплощения\" данных после последнего сверточного слоя будет ли глобальный усредняющий пулинг лучше? Эта стратегия используется, например, в  сети Google Inception  и в Остаточных (Residual) сетях.\n",
    "- **Регуляризация**: Будет ли какая-то регуляризация повышать эффективность сети? Может быть, затухание весов или dropout?\n",
    "\n",
    "\n",
    "### ПРЕДУПРЕЖДЕНИЕ: Блочная нормализация/ Dropout\n",
    "Блочная нормализация (Batch Normalization) и Dropout **БУДУТ РАБОТАТЬ НЕ ПРАВИЛЬНО**, если вы используете функцию `train_part34()` с объектно-ориентированными API-интерфейсами `tf.keras.Model` или `tf.keras.Sequential`; если вы хотите добавить слои нормализации в цикл обучения, то Вы **должны использовать функциональный API-интерфейс tf.layers**.\n",
    "\n",
    "Мы написали `train_part34 ()`, чтобы явно продемонстрировать, как работает TensorFlow; однако есть некоторые тонкости, которые затрудняют обработку объектно-ориентированного слоя блочной нормализации  в простом цикле обучения. На практике оба модуля `tf.keras` и` tf` предоставляют API высокого уровня, которые создают цикл обучения для вас, например [keras.fit] (https://keras.io/models/sequential/) и [tf. Estimator] (https://www.tensorflow.org/programmers_guide/estimators), оба из них будут корректно осуществлять блочную нормализацию  при использовании объектно-ориентированного API.\n",
    "\n",
    "### Подсказки для обучения\n",
    "Для каждой сетевой архитектуры, с которой вы экспериментируюте, вы должны выбрать скорость обучения и другие гиперпараметры. При этом есть несколько важных моментов, которые нужно иметь в виду:\n",
    "\n",
    "- Если параметры работают хорошо, вы должны видеть улучшение в течение нескольких сотен итераций;\n",
    "- Помните о грубой и тонкой настройке гиперпараметров: начните с проверки  гиперпараметров в широком диапазоне   всего на нескольких обучающих итерациях, чтобы найти комбинации параметров, которые работают вообще;\n",
    "- После того, как вы найдете несколько наборов параметров, которые работают,  найдите их более точные значения. Возможно, вам придется проводить обучение при большом числе эпох.\n",
    "- Вы должны использовать валидационное множество для поиска гиперпараметров.\n",
    "\n",
    "### Движемся все выше и выше\n",
    "Если вы ощущаете энтузиазм, есть много других функций, которые можно реализовать, чтобы попытаться повысить эффективность. Вы **не обязаны** их реализовывать, но не упустите шанс, если у вас есть время!\n",
    "\n",
    "- Альтернативные оптимизаторы: вы можете попробовать Адам, Адаград, RMSprop и т. д.;\n",
    "- Альтернативные функции активации, такие как  ReLU с утечкой, параметрическое ReLU, ELU или MaxOut;\n",
    "- Ансамбли моделей;\n",
    "- Расширение набора данных;\n",
    "- Новые архитектуры.\n",
    "\n",
    "- [ResNets](https://arxiv.org/abs/1512.03385) , где вход  предыдущего слоя добавляется к выходу.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) , где входы предыдущих слоев объединяются вместе.\n",
    "  - [Этот блог содержит подробный обзор](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "  \n",
    "### Успешного обучения! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying to restore last checkpoint ...\n",
      "\n",
      "Failed to restore checkpoint. Initializing variables instead.\n",
      "\n",
      "Epoch: 1/60\n",
      "\n",
      "Global step:     1 - [>-----------------------------]   0% - acc: 0.0938 - loss: 2.3014 - 54.0 sample/sec\n",
      "Global step:    11 - [>-----------------------------]   3% - acc: 0.0859 - loss: 2.3058 - 57.8 sample/sec\n",
      "Global step:    21 - [=>----------------------------]   5% - acc: 0.2109 - loss: 2.2199 - 92.2 sample/sec\n",
      "Global step:    31 - [==>---------------------------]   8% - acc: 0.2969 - loss: 2.1591 - 34.7 sample/sec\n",
      "Global step:    41 - [==>---------------------------]  10% - acc: 0.2031 - loss: 2.2281 - 97.7 sample/sec\n",
      "Global step:    51 - [===>--------------------------]  13% - acc: 0.3359 - loss: 2.1453 - 35.0 sample/sec\n",
      "Global step:    61 - [====>-------------------------]  15% - acc: 0.3594 - loss: 2.1018 - 95.4 sample/sec\n",
      "Global step:    71 - [=====>------------------------]  18% - acc: 0.2578 - loss: 2.2002 - 44.0 sample/sec\n",
      "Global step:    81 - [=====>------------------------]  20% - acc: 0.2578 - loss: 2.1897 - 48.8 sample/sec\n",
      "Global step:    91 - [======>-----------------------]  23% - acc: 0.3281 - loss: 2.1211 - 77.2 sample/sec\n",
      "Global step:   101 - [=======>----------------------]  26% - acc: 0.2734 - loss: 2.1929 - 30.4 sample/sec\n",
      "Global step:   111 - [========>---------------------]  28% - acc: 0.3906 - loss: 2.0980 - 29.3 sample/sec\n",
      "Global step:   121 - [========>---------------------]  31% - acc: 0.3359 - loss: 2.1165 - 90.5 sample/sec\n",
      "Global step:   131 - [=========>--------------------]  33% - acc: 0.2969 - loss: 2.1459 - 90.6 sample/sec\n",
      "Global step:   141 - [==========>-------------------]  36% - acc: 0.4375 - loss: 2.0148 - 33.1 sample/sec\n",
      "Global step:   151 - [===========>------------------]  38% - acc: 0.3047 - loss: 2.1416 - 34.9 sample/sec\n",
      "Global step:   161 - [===========>------------------]  41% - acc: 0.3438 - loss: 2.1189 - 45.9 sample/sec\n",
      "Global step:   171 - [============>-----------------]  43% - acc: 0.3438 - loss: 2.1212 - 90.9 sample/sec\n",
      "Global step:   181 - [=============>----------------]  46% - acc: 0.4141 - loss: 2.0433 - 39.4 sample/sec\n",
      "Global step:   191 - [==============>---------------]  49% - acc: 0.4141 - loss: 2.0342 - 57.1 sample/sec\n",
      "Global step:   201 - [==============>---------------]  51% - acc: 0.3281 - loss: 2.1153 - 93.2 sample/sec\n",
      "Global step:   211 - [===============>--------------]  54% - acc: 0.4062 - loss: 2.0644 - 50.6 sample/sec\n",
      "Global step:   221 - [================>-------------]  56% - acc: 0.3359 - loss: 2.0991 - 93.6 sample/sec\n",
      "Global step:   231 - [=================>------------]  59% - acc: 0.3203 - loss: 2.1272 - 56.0 sample/sec\n",
      "Global step:   241 - [=================>------------]  61% - acc: 0.3438 - loss: 2.1089 - 31.5 sample/sec\n",
      "Global step:   251 - [==================>-----------]  64% - acc: 0.3125 - loss: 2.1368 - 93.4 sample/sec\n",
      "Global step:   261 - [===================>----------]  66% - acc: 0.3047 - loss: 2.1309 - 94.5 sample/sec\n",
      "Global step:   271 - [====================>---------]  69% - acc: 0.3906 - loss: 2.0654 - 37.5 sample/sec\n",
      "Global step:   281 - [====================>---------]  72% - acc: 0.4141 - loss: 2.0163 - 93.4 sample/sec\n",
      "Global step:   291 - [=====================>--------]  74% - acc: 0.3516 - loss: 2.1002 - 64.7 sample/sec\n",
      "Global step:   301 - [======================>-------]  77% - acc: 0.3906 - loss: 2.0663 - 61.1 sample/sec\n",
      "Global step:   311 - [======================>-------]  79% - acc: 0.3203 - loss: 2.1440 - 94.4 sample/sec\n",
      "Global step:   321 - [=======================>------]  82% - acc: 0.2969 - loss: 2.1590 - 31.7 sample/sec\n",
      "Global step:   331 - [========================>-----]  84% - acc: 0.3984 - loss: 2.0518 - 94.6 sample/sec\n",
      "Global step:   341 - [=========================>----]  87% - acc: 0.3828 - loss: 2.0664 - 95.7 sample/sec\n",
      "Global step:   351 - [==========================>---]  90% - acc: 0.3047 - loss: 2.1305 - 34.2 sample/sec\n",
      "Global step:   361 - [==========================>---]  92% - acc: 0.4688 - loss: 1.9960 - 93.1 sample/sec\n",
      "Global step:   371 - [===========================>--]  95% - acc: 0.3516 - loss: 2.0881 - 44.0 sample/sec\n",
      "Global step:   381 - [============================>-]  97% - acc: 0.4062 - loss: 2.0397 - 69.6 sample/sec\n",
      "Global step:   391 - [=============================>] 100% - acc: 0.4125 - loss: 2.0479 - 148.1 sample/sec\n",
      "\n",
      "Epoch 1 - accuracy: 44.52% (4452/10000) - time: 00:15:08.74\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 2/60\n",
      "\n",
      "Global step:   392 - [>-----------------------------]   0% - acc: 0.4531 - loss: 1.9989 - 88.0 sample/sec\n",
      "Global step:   402 - [>-----------------------------]   3% - acc: 0.4062 - loss: 2.0688 - 94.5 sample/sec\n",
      "Global step:   412 - [=>----------------------------]   5% - acc: 0.4531 - loss: 2.0022 - 33.0 sample/sec\n",
      "Global step:   422 - [==>---------------------------]   8% - acc: 0.3906 - loss: 2.0544 - 84.3 sample/sec\n",
      "Global step:   432 - [==>---------------------------]  10% - acc: 0.4453 - loss: 2.0343 - 92.2 sample/sec\n",
      "Global step:   442 - [===>--------------------------]  13% - acc: 0.4453 - loss: 2.0119 - 32.6 sample/sec\n",
      "Global step:   452 - [====>-------------------------]  15% - acc: 0.4766 - loss: 2.0020 - 89.9 sample/sec\n",
      "Global step:   462 - [=====>------------------------]  18% - acc: 0.3828 - loss: 2.0685 - 64.0 sample/sec\n",
      "Global step:   472 - [=====>------------------------]  20% - acc: 0.4688 - loss: 1.9861 - 56.0 sample/sec\n",
      "Global step:   482 - [======>-----------------------]  23% - acc: 0.4844 - loss: 1.9631 - 93.6 sample/sec\n",
      "Global step:   492 - [=======>----------------------]  26% - acc: 0.4375 - loss: 2.0189 - 39.1 sample/sec\n",
      "Global step:   502 - [========>---------------------]  28% - acc: 0.4531 - loss: 2.0076 - 91.1 sample/sec\n",
      "Global step:   512 - [========>---------------------]  31% - acc: 0.4688 - loss: 1.9971 - 95.7 sample/sec\n",
      "Global step:   522 - [=========>--------------------]  33% - acc: 0.4844 - loss: 1.9771 - 41.8 sample/sec\n",
      "Global step:   532 - [==========>-------------------]  36% - acc: 0.5078 - loss: 1.9615 - 92.4 sample/sec\n",
      "Global step:   542 - [===========>------------------]  38% - acc: 0.4688 - loss: 1.9833 - 43.0 sample/sec\n",
      "Global step:   552 - [===========>------------------]  41% - acc: 0.4219 - loss: 2.0340 - 92.0 sample/sec\n",
      "Global step:   562 - [============>-----------------]  43% - acc: 0.4297 - loss: 2.0320 - 91.7 sample/sec\n",
      "Global step:   572 - [=============>----------------]  46% - acc: 0.5625 - loss: 1.9126 - 32.7 sample/sec\n",
      "Global step:   582 - [==============>---------------]  49% - acc: 0.4922 - loss: 1.9527 - 48.2 sample/sec\n",
      "Global step:   592 - [==============>---------------]  51% - acc: 0.5000 - loss: 1.9649 - 89.2 sample/sec\n",
      "Global step:   602 - [===============>--------------]  54% - acc: 0.4922 - loss: 1.9710 - 90.8 sample/sec\n",
      "Global step:   612 - [================>-------------]  56% - acc: 0.5312 - loss: 1.9410 - 42.0 sample/sec\n",
      "Global step:   622 - [=================>------------]  59% - acc: 0.4531 - loss: 1.9882 - 92.0 sample/sec\n",
      "Global step:   632 - [=================>------------]  61% - acc: 0.4766 - loss: 1.9870 - 94.4 sample/sec\n",
      "Global step:   642 - [==================>-----------]  64% - acc: 0.5469 - loss: 1.9339 - 37.0 sample/sec\n",
      "Global step:   652 - [===================>----------]  66% - acc: 0.4531 - loss: 2.0081 - 89.1 sample/sec\n",
      "Global step:   662 - [====================>---------]  69% - acc: 0.4922 - loss: 1.9544 - 77.1 sample/sec\n",
      "Global step:   672 - [====================>---------]  72% - acc: 0.4531 - loss: 1.9943 - 44.6 sample/sec\n",
      "Global step:   682 - [=====================>--------]  74% - acc: 0.3828 - loss: 2.0642 - 91.8 sample/sec\n",
      "Global step:   692 - [======================>-------]  77% - acc: 0.5859 - loss: 1.8714 - 49.9 sample/sec\n",
      "Global step:   702 - [======================>-------]  79% - acc: 0.4531 - loss: 2.0079 - 93.2 sample/sec\n",
      "Global step:   712 - [=======================>------]  82% - acc: 0.4844 - loss: 1.9754 - 84.7 sample/sec\n",
      "Global step:   722 - [========================>-----]  84% - acc: 0.6094 - loss: 1.8344 - 31.2 sample/sec\n",
      "Global step:   732 - [=========================>----]  87% - acc: 0.4609 - loss: 1.9857 - 87.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:   742 - [==========================>---]  90% - acc: 0.4688 - loss: 1.9928 - 79.7 sample/sec\n",
      "Global step:   752 - [==========================>---]  92% - acc: 0.5703 - loss: 1.8853 - 86.7 sample/sec\n",
      "Global step:   762 - [===========================>--]  95% - acc: 0.5547 - loss: 1.9256 - 45.9 sample/sec\n",
      "Global step:   772 - [============================>-]  97% - acc: 0.5391 - loss: 1.9208 - 64.3 sample/sec\n",
      "Global step:   782 - [=============================>] 100% - acc: 0.5375 - loss: 1.9334 - 144.5 sample/sec\n",
      "\n",
      "Epoch 2 - accuracy: 54.34% (5434/10000) - time: 00:14:58.77\n",
      "This epoch receive better accuracy: 54.34 > 44.52. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 3/60\n",
      "\n",
      "Global step:   783 - [>-----------------------------]   0% - acc: 0.5469 - loss: 1.8875 - 39.9 sample/sec\n",
      "Global step:   793 - [>-----------------------------]   3% - acc: 0.5703 - loss: 1.9161 - 27.1 sample/sec\n",
      "Global step:   803 - [=>----------------------------]   5% - acc: 0.6016 - loss: 1.8473 - 49.1 sample/sec\n",
      "Global step:   813 - [==>---------------------------]   8% - acc: 0.5156 - loss: 1.9350 - 90.2 sample/sec\n",
      "Global step:   823 - [==>---------------------------]  10% - acc: 0.5312 - loss: 1.9248 - 88.1 sample/sec\n",
      "Global step:   833 - [===>--------------------------]  13% - acc: 0.5703 - loss: 1.8949 - 38.9 sample/sec\n",
      "Global step:   843 - [====>-------------------------]  15% - acc: 0.4453 - loss: 2.0028 - 43.3 sample/sec\n",
      "Global step:   853 - [=====>------------------------]  18% - acc: 0.5469 - loss: 1.9186 - 80.6 sample/sec\n",
      "Global step:   863 - [=====>------------------------]  20% - acc: 0.5859 - loss: 1.8963 - 93.6 sample/sec\n",
      "Global step:   873 - [======>-----------------------]  23% - acc: 0.6172 - loss: 1.8432 - 36.7 sample/sec\n",
      "Global step:   883 - [=======>----------------------]  26% - acc: 0.6094 - loss: 1.8709 - 32.7 sample/sec\n",
      "Global step:   893 - [========>---------------------]  28% - acc: 0.5312 - loss: 1.9191 - 92.4 sample/sec\n",
      "Global step:   903 - [========>---------------------]  31% - acc: 0.6172 - loss: 1.8555 - 66.2 sample/sec\n",
      "Global step:   913 - [=========>--------------------]  33% - acc: 0.6562 - loss: 1.8198 - 47.8 sample/sec\n",
      "Global step:   923 - [==========>-------------------]  36% - acc: 0.6016 - loss: 1.8666 - 90.3 sample/sec\n",
      "Global step:   933 - [===========>------------------]  38% - acc: 0.6094 - loss: 1.8407 - 76.7 sample/sec\n",
      "Global step:   943 - [===========>------------------]  41% - acc: 0.5469 - loss: 1.8950 - 36.4 sample/sec\n",
      "Global step:   953 - [============>-----------------]  43% - acc: 0.5156 - loss: 1.9441 - 92.3 sample/sec\n",
      "Global step:   963 - [=============>----------------]  46% - acc: 0.5938 - loss: 1.8536 - 51.5 sample/sec\n",
      "Global step:   973 - [==============>---------------]  49% - acc: 0.6328 - loss: 1.8436 - 65.4 sample/sec\n",
      "Global step:   983 - [==============>---------------]  51% - acc: 0.5625 - loss: 1.8896 - 79.1 sample/sec\n",
      "Global step:   993 - [===============>--------------]  54% - acc: 0.5938 - loss: 1.8687 - 92.5 sample/sec\n",
      "Global step:  1003 - [================>-------------]  56% - acc: 0.6172 - loss: 1.8556 - 83.9 sample/sec\n",
      "Global step:  1013 - [=================>------------]  59% - acc: 0.5625 - loss: 1.8905 - 40.9 sample/sec\n",
      "Global step:  1023 - [=================>------------]  61% - acc: 0.5547 - loss: 1.9060 - 71.9 sample/sec\n",
      "Global step:  1033 - [==================>-----------]  64% - acc: 0.6094 - loss: 1.8640 - 64.8 sample/sec\n",
      "Global step:  1043 - [===================>----------]  66% - acc: 0.5625 - loss: 1.8973 - 90.1 sample/sec\n",
      "Global step:  1053 - [====================>---------]  69% - acc: 0.6406 - loss: 1.8255 - 53.9 sample/sec\n",
      "Global step:  1063 - [====================>---------]  72% - acc: 0.6016 - loss: 1.8515 - 37.7 sample/sec\n",
      "Global step:  1073 - [=====================>--------]  74% - acc: 0.5625 - loss: 1.8932 - 88.9 sample/sec\n",
      "Global step:  1083 - [======================>-------]  77% - acc: 0.7031 - loss: 1.7714 - 58.2 sample/sec\n",
      "Global step:  1093 - [======================>-------]  79% - acc: 0.5312 - loss: 1.9148 - 39.8 sample/sec\n",
      "Global step:  1103 - [=======================>------]  82% - acc: 0.4766 - loss: 1.9621 - 91.6 sample/sec\n",
      "Global step:  1113 - [========================>-----]  84% - acc: 0.6406 - loss: 1.8117 - 52.6 sample/sec\n",
      "Global step:  1123 - [=========================>----]  87% - acc: 0.6172 - loss: 1.8457 - 40.2 sample/sec\n",
      "Global step:  1133 - [==========================>---]  90% - acc: 0.5625 - loss: 1.8865 - 60.0 sample/sec\n",
      "Global step:  1143 - [==========================>---]  92% - acc: 0.6875 - loss: 1.7813 - 90.7 sample/sec\n",
      "Global step:  1153 - [===========================>--]  95% - acc: 0.6328 - loss: 1.8279 - 45.9 sample/sec\n",
      "Global step:  1163 - [============================>-]  97% - acc: 0.6641 - loss: 1.7924 - 81.4 sample/sec\n",
      "Global step:  1173 - [=============================>] 100% - acc: 0.7000 - loss: 1.7683 - 116.8 sample/sec\n",
      "\n",
      "Epoch 3 - accuracy: 61.16% (6116/10000) - time: 00:15:45.25\n",
      "This epoch receive better accuracy: 61.16 > 54.34. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 4/60\n",
      "\n",
      "Global step:  1174 - [>-----------------------------]   0% - acc: 0.6328 - loss: 1.8252 - 43.0 sample/sec\n",
      "Global step:  1184 - [>-----------------------------]   3% - acc: 0.6484 - loss: 1.8182 - 59.8 sample/sec\n",
      "Global step:  1194 - [=>----------------------------]   5% - acc: 0.6562 - loss: 1.7880 - 91.7 sample/sec\n",
      "Global step:  1204 - [==>---------------------------]   8% - acc: 0.5938 - loss: 1.8696 - 50.7 sample/sec\n",
      "Global step:  1214 - [==>---------------------------]  10% - acc: 0.6016 - loss: 1.8418 - 77.1 sample/sec\n",
      "Global step:  1224 - [===>--------------------------]  13% - acc: 0.6406 - loss: 1.8259 - 92.0 sample/sec\n",
      "Global step:  1234 - [====>-------------------------]  15% - acc: 0.6172 - loss: 1.8348 - 64.0 sample/sec\n",
      "Global step:  1244 - [=====>------------------------]  18% - acc: 0.5938 - loss: 1.8624 - 39.6 sample/sec\n",
      "Global step:  1254 - [=====>------------------------]  20% - acc: 0.6172 - loss: 1.8288 - 89.1 sample/sec\n",
      "Global step:  1264 - [======>-----------------------]  23% - acc: 0.6562 - loss: 1.7892 - 59.1 sample/sec\n",
      "Global step:  1274 - [=======>----------------------]  26% - acc: 0.6719 - loss: 1.7807 - 45.8 sample/sec\n",
      "Global step:  1284 - [========>---------------------]  28% - acc: 0.5781 - loss: 1.8692 - 90.8 sample/sec\n",
      "Global step:  1294 - [========>---------------------]  31% - acc: 0.6641 - loss: 1.7921 - 46.2 sample/sec\n",
      "Global step:  1304 - [=========>--------------------]  33% - acc: 0.6875 - loss: 1.7711 - 51.1 sample/sec\n",
      "Global step:  1314 - [==========>-------------------]  36% - acc: 0.5547 - loss: 1.8843 - 91.2 sample/sec\n",
      "Global step:  1324 - [===========>------------------]  38% - acc: 0.6484 - loss: 1.8039 - 63.9 sample/sec\n",
      "Global step:  1334 - [===========>------------------]  41% - acc: 0.6328 - loss: 1.8238 - 45.3 sample/sec\n",
      "Global step:  1344 - [============>-----------------]  43% - acc: 0.5938 - loss: 1.8711 - 90.9 sample/sec\n",
      "Global step:  1354 - [=============>----------------]  46% - acc: 0.7188 - loss: 1.7351 - 54.4 sample/sec\n",
      "Global step:  1364 - [==============>---------------]  49% - acc: 0.6406 - loss: 1.8075 - 31.3 sample/sec\n",
      "Global step:  1374 - [==============>---------------]  51% - acc: 0.5703 - loss: 1.8791 - 91.5 sample/sec\n",
      "Global step:  1384 - [===============>--------------]  54% - acc: 0.6328 - loss: 1.8090 - 92.0 sample/sec\n",
      "Global step:  1394 - [================>-------------]  56% - acc: 0.6953 - loss: 1.7650 - 32.8 sample/sec\n",
      "Global step:  1404 - [=================>------------]  59% - acc: 0.6562 - loss: 1.8213 - 92.1 sample/sec\n",
      "Global step:  1414 - [=================>------------]  61% - acc: 0.5703 - loss: 1.8778 - 92.3 sample/sec\n",
      "Global step:  1424 - [==================>-----------]  64% - acc: 0.6641 - loss: 1.8056 - 41.4 sample/sec\n",
      "Global step:  1434 - [===================>----------]  66% - acc: 0.6172 - loss: 1.8487 - 92.0 sample/sec\n",
      "Global step:  1444 - [====================>---------]  69% - acc: 0.6406 - loss: 1.8131 - 50.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  1454 - [====================>---------]  72% - acc: 0.6172 - loss: 1.8371 - 80.7 sample/sec\n",
      "Global step:  1464 - [=====================>--------]  74% - acc: 0.5781 - loss: 1.8694 - 75.9 sample/sec\n",
      "Global step:  1474 - [======================>-------]  77% - acc: 0.6094 - loss: 1.8369 - 69.5 sample/sec\n",
      "Global step:  1484 - [======================>-------]  79% - acc: 0.5859 - loss: 1.8496 - 44.1 sample/sec\n",
      "Global step:  1494 - [=======================>------]  82% - acc: 0.5859 - loss: 1.8832 - 92.2 sample/sec\n",
      "Global step:  1504 - [========================>-----]  84% - acc: 0.6875 - loss: 1.7656 - 81.1 sample/sec\n",
      "Global step:  1514 - [=========================>----]  87% - acc: 0.6172 - loss: 1.8229 - 42.3 sample/sec\n",
      "Global step:  1524 - [==========================>---]  90% - acc: 0.5938 - loss: 1.8492 - 64.5 sample/sec\n",
      "Global step:  1534 - [==========================>---]  92% - acc: 0.7109 - loss: 1.7513 - 85.8 sample/sec\n",
      "Global step:  1544 - [===========================>--]  95% - acc: 0.6641 - loss: 1.7977 - 49.9 sample/sec\n",
      "Global step:  1554 - [============================>-]  97% - acc: 0.7266 - loss: 1.7486 - 41.0 sample/sec\n",
      "Global step:  1564 - [=============================>] 100% - acc: 0.6375 - loss: 1.8288 - 143.7 sample/sec\n",
      "\n",
      "Epoch 4 - accuracy: 64.32% (6432/10000) - time: 00:15:02.07\n",
      "This epoch receive better accuracy: 64.32 > 61.16. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 5/60\n",
      "\n",
      "Global step:  1565 - [>-----------------------------]   0% - acc: 0.6562 - loss: 1.7984 - 95.9 sample/sec\n",
      "Global step:  1575 - [>-----------------------------]   3% - acc: 0.6406 - loss: 1.8061 - 94.3 sample/sec\n",
      "Global step:  1585 - [=>----------------------------]   5% - acc: 0.7109 - loss: 1.7318 - 30.1 sample/sec\n",
      "Global step:  1595 - [==>---------------------------]   8% - acc: 0.6484 - loss: 1.8107 - 90.2 sample/sec\n",
      "Global step:  1605 - [==>---------------------------]  10% - acc: 0.6406 - loss: 1.8233 - 92.8 sample/sec\n",
      "Global step:  1615 - [===>--------------------------]  13% - acc: 0.6484 - loss: 1.8118 - 34.8 sample/sec\n",
      "Global step:  1625 - [====>-------------------------]  15% - acc: 0.6641 - loss: 1.7971 - 91.8 sample/sec\n",
      "Global step:  1635 - [=====>------------------------]  18% - acc: 0.6562 - loss: 1.8048 - 51.5 sample/sec\n",
      "Global step:  1645 - [=====>------------------------]  20% - acc: 0.6562 - loss: 1.8007 - 40.4 sample/sec\n",
      "Global step:  1655 - [======>-----------------------]  23% - acc: 0.6719 - loss: 1.7778 - 89.3 sample/sec\n",
      "Global step:  1665 - [=======>----------------------]  26% - acc: 0.6953 - loss: 1.7634 - 85.3 sample/sec\n",
      "Global step:  1675 - [========>---------------------]  28% - acc: 0.6797 - loss: 1.7853 - 52.3 sample/sec\n",
      "Global step:  1685 - [========>---------------------]  31% - acc: 0.7500 - loss: 1.7082 - 91.3 sample/sec\n",
      "Global step:  1695 - [=========>--------------------]  33% - acc: 0.6797 - loss: 1.7791 - 36.8 sample/sec\n",
      "Global step:  1705 - [==========>-------------------]  36% - acc: 0.6484 - loss: 1.8098 - 90.4 sample/sec\n",
      "Global step:  1715 - [===========>------------------]  38% - acc: 0.6406 - loss: 1.8124 - 90.3 sample/sec\n",
      "Global step:  1725 - [===========>------------------]  41% - acc: 0.6797 - loss: 1.7871 - 33.6 sample/sec\n",
      "Global step:  1735 - [============>-----------------]  43% - acc: 0.6484 - loss: 1.8078 - 49.0 sample/sec\n",
      "Global step:  1745 - [=============>----------------]  46% - acc: 0.7422 - loss: 1.7137 - 83.7 sample/sec\n",
      "Global step:  1755 - [==============>---------------]  49% - acc: 0.6953 - loss: 1.7646 - 72.4 sample/sec\n",
      "Global step:  1765 - [==============>---------------]  51% - acc: 0.6484 - loss: 1.8312 - 46.5 sample/sec\n",
      "Global step:  1775 - [===============>--------------]  54% - acc: 0.6719 - loss: 1.7980 - 82.5 sample/sec\n",
      "Global step:  1785 - [================>-------------]  56% - acc: 0.7031 - loss: 1.7495 - 59.4 sample/sec\n",
      "Global step:  1795 - [=================>------------]  59% - acc: 0.6797 - loss: 1.7802 - 54.9 sample/sec\n",
      "Global step:  1805 - [=================>------------]  61% - acc: 0.6250 - loss: 1.8282 - 81.8 sample/sec\n",
      "Global step:  1815 - [==================>-----------]  64% - acc: 0.6797 - loss: 1.7738 - 92.7 sample/sec\n",
      "Global step:  1825 - [===================>----------]  66% - acc: 0.6328 - loss: 1.8278 - 33.7 sample/sec\n",
      "Global step:  1835 - [====================>---------]  69% - acc: 0.6641 - loss: 1.8067 - 38.3 sample/sec\n",
      "Global step:  1845 - [====================>---------]  72% - acc: 0.6016 - loss: 1.8592 - 91.6 sample/sec\n",
      "Global step:  1855 - [=====================>--------]  74% - acc: 0.6172 - loss: 1.8460 - 39.5 sample/sec\n",
      "Global step:  1865 - [======================>-------]  77% - acc: 0.7109 - loss: 1.7395 - 91.4 sample/sec\n",
      "Global step:  1875 - [======================>-------]  79% - acc: 0.6406 - loss: 1.8388 - 92.4 sample/sec\n",
      "Global step:  1885 - [=======================>------]  82% - acc: 0.5859 - loss: 1.8599 - 37.7 sample/sec\n",
      "Global step:  1895 - [========================>-----]  84% - acc: 0.7734 - loss: 1.6959 - 75.1 sample/sec\n",
      "Global step:  1905 - [=========================>----]  87% - acc: 0.6406 - loss: 1.8182 - 93.2 sample/sec\n",
      "Global step:  1915 - [==========================>---]  90% - acc: 0.6484 - loss: 1.8138 - 34.1 sample/sec\n",
      "Global step:  1925 - [==========================>---]  92% - acc: 0.7500 - loss: 1.7151 - 89.0 sample/sec\n",
      "Global step:  1935 - [===========================>--]  95% - acc: 0.6875 - loss: 1.7868 - 89.3 sample/sec\n",
      "Global step:  1945 - [============================>-]  97% - acc: 0.6953 - loss: 1.7654 - 47.5 sample/sec\n",
      "Global step:  1955 - [=============================>] 100% - acc: 0.6750 - loss: 1.7762 - 141.3 sample/sec\n",
      "\n",
      "Epoch 5 - accuracy: 67.77% (6777/10000) - time: 00:15:06.88\n",
      "This epoch receive better accuracy: 67.77 > 64.32. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 6/60\n",
      "\n",
      "Global step:  1956 - [>-----------------------------]   0% - acc: 0.7578 - loss: 1.6958 - 42.3 sample/sec\n",
      "Global step:  1966 - [>-----------------------------]   3% - acc: 0.7188 - loss: 1.7498 - 81.0 sample/sec\n",
      "Global step:  1976 - [=>----------------------------]   5% - acc: 0.7734 - loss: 1.6867 - 72.2 sample/sec\n",
      "Global step:  1986 - [==>---------------------------]   8% - acc: 0.6953 - loss: 1.7566 - 90.3 sample/sec\n",
      "Global step:  1996 - [==>---------------------------]  10% - acc: 0.6797 - loss: 1.7768 - 91.7 sample/sec\n",
      "Global step:  2006 - [===>--------------------------]  13% - acc: 0.7266 - loss: 1.7319 - 28.2 sample/sec\n",
      "Global step:  2016 - [====>-------------------------]  15% - acc: 0.6875 - loss: 1.7625 - 87.4 sample/sec\n",
      "Global step:  2026 - [=====>------------------------]  18% - acc: 0.6562 - loss: 1.8056 - 76.6 sample/sec\n",
      "Global step:  2036 - [=====>------------------------]  20% - acc: 0.6953 - loss: 1.7753 - 37.0 sample/sec\n",
      "Global step:  2046 - [======>-----------------------]  23% - acc: 0.7578 - loss: 1.7310 - 33.1 sample/sec\n",
      "Global step:  2056 - [=======>----------------------]  26% - acc: 0.7656 - loss: 1.7109 - 86.8 sample/sec\n",
      "Global step:  2066 - [========>---------------------]  28% - acc: 0.6562 - loss: 1.8076 - 91.2 sample/sec\n",
      "Global step:  2076 - [========>---------------------]  31% - acc: 0.7188 - loss: 1.7541 - 46.7 sample/sec\n",
      "Global step:  2086 - [=========>--------------------]  33% - acc: 0.6719 - loss: 1.7875 - 91.4 sample/sec\n",
      "Global step:  2096 - [==========>-------------------]  36% - acc: 0.7188 - loss: 1.7449 - 94.0 sample/sec\n",
      "Global step:  2106 - [===========>------------------]  38% - acc: 0.7188 - loss: 1.7469 - 36.6 sample/sec\n",
      "Global step:  2116 - [===========>------------------]  41% - acc: 0.7188 - loss: 1.7369 - 91.0 sample/sec\n",
      "Global step:  2126 - [============>-----------------]  43% - acc: 0.7031 - loss: 1.7658 - 71.4 sample/sec\n",
      "Global step:  2136 - [=============>----------------]  46% - acc: 0.7891 - loss: 1.6878 - 88.2 sample/sec\n",
      "Global step:  2146 - [==============>---------------]  49% - acc: 0.7109 - loss: 1.7554 - 65.2 sample/sec\n",
      "Global step:  2156 - [==============>---------------]  51% - acc: 0.6641 - loss: 1.7972 - 87.1 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  2166 - [===============>--------------]  54% - acc: 0.7422 - loss: 1.7296 - 63.8 sample/sec\n",
      "Global step:  2176 - [================>-------------]  56% - acc: 0.7266 - loss: 1.7195 - 36.6 sample/sec\n",
      "Global step:  2186 - [=================>------------]  59% - acc: 0.7188 - loss: 1.7345 - 65.5 sample/sec\n",
      "Global step:  2196 - [=================>------------]  61% - acc: 0.6719 - loss: 1.7773 - 79.7 sample/sec\n",
      "Global step:  2206 - [==================>-----------]  64% - acc: 0.7188 - loss: 1.7446 - 41.6 sample/sec\n",
      "Global step:  2216 - [===================>----------]  66% - acc: 0.7031 - loss: 1.7570 - 25.4 sample/sec\n",
      "Global step:  2226 - [====================>---------]  69% - acc: 0.6875 - loss: 1.7802 - 26.5 sample/sec\n",
      "Global step:  2236 - [====================>---------]  72% - acc: 0.6719 - loss: 1.7956 - 69.6 sample/sec\n",
      "Global step:  2246 - [=====================>--------]  74% - acc: 0.6719 - loss: 1.7915 - 26.3 sample/sec\n",
      "Global step:  2256 - [======================>-------]  77% - acc: 0.7031 - loss: 1.7430 - 43.2 sample/sec\n",
      "Global step:  2266 - [======================>-------]  79% - acc: 0.6719 - loss: 1.7919 - 47.8 sample/sec\n",
      "Global step:  2276 - [=======================>------]  82% - acc: 0.6484 - loss: 1.8091 - 69.4 sample/sec\n",
      "Global step:  2286 - [========================>-----]  84% - acc: 0.7812 - loss: 1.6877 - 26.0 sample/sec\n",
      "Global step:  2296 - [=========================>----]  87% - acc: 0.7109 - loss: 1.7549 - 71.1 sample/sec\n",
      "Global step:  2306 - [==========================>---]  90% - acc: 0.7422 - loss: 1.7316 - 24.8 sample/sec\n",
      "Global step:  2316 - [==========================>---]  92% - acc: 0.7578 - loss: 1.7240 - 28.1 sample/sec\n",
      "Global step:  2326 - [===========================>--]  95% - acc: 0.7422 - loss: 1.7266 - 65.7 sample/sec\n",
      "Global step:  2336 - [============================>-]  97% - acc: 0.7188 - loss: 1.7372 - 63.2 sample/sec\n",
      "Global step:  2346 - [=============================>] 100% - acc: 0.7500 - loss: 1.7256 - 98.8 sample/sec\n",
      "\n",
      "Epoch 6 - accuracy: 70.15% (7015/10000) - time: 00:18:56.62\n",
      "This epoch receive better accuracy: 70.15 > 67.77. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 7/60\n",
      "\n",
      "Global step:  2347 - [>-----------------------------]   0% - acc: 0.7969 - loss: 1.6657 - 59.7 sample/sec\n",
      "Global step:  2357 - [>-----------------------------]   3% - acc: 0.7344 - loss: 1.7210 - 29.8 sample/sec\n",
      "Global step:  2367 - [=>----------------------------]   5% - acc: 0.7891 - loss: 1.6779 - 61.1 sample/sec\n",
      "Global step:  2377 - [==>---------------------------]   8% - acc: 0.7266 - loss: 1.7384 - 23.4 sample/sec\n",
      "Global step:  2387 - [==>---------------------------]  10% - acc: 0.6484 - loss: 1.7959 - 40.2 sample/sec\n",
      "Global step:  2397 - [===>--------------------------]  13% - acc: 0.7734 - loss: 1.7053 - 38.1 sample/sec\n",
      "Global step:  2407 - [====>-------------------------]  15% - acc: 0.7344 - loss: 1.7218 - 73.1 sample/sec\n",
      "Global step:  2417 - [=====>------------------------]  18% - acc: 0.6328 - loss: 1.8023 - 28.0 sample/sec\n",
      "Global step:  2427 - [=====>------------------------]  20% - acc: 0.7578 - loss: 1.7103 - 46.1 sample/sec\n",
      "Global step:  2437 - [======>-----------------------]  23% - acc: 0.7578 - loss: 1.7147 - 37.9 sample/sec\n",
      "Global step:  2447 - [=======>----------------------]  26% - acc: 0.7656 - loss: 1.6925 - 77.2 sample/sec\n",
      "Global step:  2457 - [========>---------------------]  28% - acc: 0.7031 - loss: 1.7601 - 26.8 sample/sec\n",
      "Global step:  2467 - [========>---------------------]  31% - acc: 0.7344 - loss: 1.7374 - 73.3 sample/sec\n",
      "Global step:  2477 - [=========>--------------------]  33% - acc: 0.7266 - loss: 1.7431 - 36.3 sample/sec\n",
      "Global step:  2487 - [==========>-------------------]  36% - acc: 0.7188 - loss: 1.7395 - 29.6 sample/sec\n",
      "Global step:  2497 - [===========>------------------]  38% - acc: 0.7500 - loss: 1.7141 - 38.6 sample/sec\n",
      "Global step:  2507 - [===========>------------------]  41% - acc: 0.7578 - loss: 1.6994 - 45.2 sample/sec\n",
      "Global step:  2517 - [============>-----------------]  43% - acc: 0.7500 - loss: 1.7149 - 82.9 sample/sec\n",
      "Global step:  2527 - [=============>----------------]  46% - acc: 0.7891 - loss: 1.6816 - 80.3 sample/sec\n",
      "Global step:  2537 - [==============>---------------]  49% - acc: 0.7031 - loss: 1.7556 - 90.2 sample/sec\n",
      "Global step:  2547 - [==============>---------------]  51% - acc: 0.7031 - loss: 1.7630 - 33.9 sample/sec\n",
      "Global step:  2557 - [===============>--------------]  54% - acc: 0.7109 - loss: 1.7484 - 94.1 sample/sec\n",
      "Global step:  2567 - [================>-------------]  56% - acc: 0.7266 - loss: 1.7304 - 40.9 sample/sec\n",
      "Global step:  2577 - [=================>------------]  59% - acc: 0.7812 - loss: 1.6874 - 90.9 sample/sec\n",
      "Global step:  2587 - [=================>------------]  61% - acc: 0.6953 - loss: 1.7653 - 95.3 sample/sec\n",
      "Global step:  2597 - [==================>-----------]  64% - acc: 0.6797 - loss: 1.7608 - 36.3 sample/sec\n",
      "Global step:  2607 - [===================>----------]  66% - acc: 0.6953 - loss: 1.7647 - 93.1 sample/sec\n",
      "Global step:  2617 - [====================>---------]  69% - acc: 0.6875 - loss: 1.7660 - 34.0 sample/sec\n",
      "Global step:  2627 - [====================>---------]  72% - acc: 0.6797 - loss: 1.7799 - 95.3 sample/sec\n",
      "Global step:  2637 - [=====================>--------]  74% - acc: 0.7266 - loss: 1.7439 - 42.5 sample/sec\n",
      "Global step:  2647 - [======================>-------]  77% - acc: 0.7891 - loss: 1.6769 - 94.2 sample/sec\n",
      "Global step:  2657 - [======================>-------]  79% - acc: 0.6953 - loss: 1.7708 - 50.0 sample/sec\n",
      "Global step:  2667 - [=======================>------]  82% - acc: 0.6797 - loss: 1.7689 - 92.8 sample/sec\n",
      "Global step:  2677 - [========================>-----]  84% - acc: 0.7969 - loss: 1.6694 - 54.7 sample/sec\n",
      "Global step:  2687 - [=========================>----]  87% - acc: 0.7188 - loss: 1.7393 - 91.9 sample/sec\n",
      "Global step:  2697 - [==========================>---]  90% - acc: 0.7422 - loss: 1.7318 - 73.6 sample/sec\n",
      "Global step:  2707 - [==========================>---]  92% - acc: 0.7734 - loss: 1.6871 - 95.7 sample/sec\n",
      "Global step:  2717 - [===========================>--]  95% - acc: 0.7734 - loss: 1.6948 - 60.4 sample/sec\n",
      "Global step:  2727 - [============================>-]  97% - acc: 0.7656 - loss: 1.6959 - 93.1 sample/sec\n",
      "Global step:  2737 - [=============================>] 100% - acc: 0.7000 - loss: 1.7542 - 151.1 sample/sec\n",
      "\n",
      "Epoch 7 - accuracy: 65.65% (6565/10000) - time: 00:17:03.34\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 8/60\n",
      "\n",
      "Global step:  2738 - [>-----------------------------]   0% - acc: 0.7031 - loss: 1.7465 - 51.2 sample/sec\n",
      "Global step:  2748 - [>-----------------------------]   3% - acc: 0.7734 - loss: 1.6882 - 95.2 sample/sec\n",
      "Global step:  2758 - [=>----------------------------]   5% - acc: 0.8047 - loss: 1.6481 - 38.5 sample/sec\n",
      "Global step:  2768 - [==>---------------------------]   8% - acc: 0.7578 - loss: 1.6979 - 76.1 sample/sec\n",
      "Global step:  2778 - [==>---------------------------]  10% - acc: 0.7188 - loss: 1.7304 - 42.4 sample/sec\n",
      "Global step:  2788 - [===>--------------------------]  13% - acc: 0.7891 - loss: 1.6773 - 44.2 sample/sec\n",
      "Global step:  2798 - [====>-------------------------]  15% - acc: 0.7500 - loss: 1.7033 - 96.4 sample/sec\n",
      "Global step:  2808 - [=====>------------------------]  18% - acc: 0.6953 - loss: 1.7619 - 58.7 sample/sec\n",
      "Global step:  2818 - [=====>------------------------]  20% - acc: 0.7266 - loss: 1.7303 - 82.7 sample/sec\n",
      "Global step:  2828 - [======>-----------------------]  23% - acc: 0.8281 - loss: 1.6345 - 91.4 sample/sec\n",
      "Global step:  2838 - [=======>----------------------]  26% - acc: 0.8047 - loss: 1.6699 - 34.8 sample/sec\n",
      "Global step:  2848 - [========>---------------------]  28% - acc: 0.7266 - loss: 1.7269 - 65.3 sample/sec\n",
      "Global step:  2858 - [========>---------------------]  31% - acc: 0.7500 - loss: 1.7047 - 94.2 sample/sec\n",
      "Global step:  2868 - [=========>--------------------]  33% - acc: 0.7266 - loss: 1.7451 - 49.8 sample/sec\n",
      "Global step:  2878 - [==========>-------------------]  36% - acc: 0.6875 - loss: 1.7640 - 86.8 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  2888 - [===========>------------------]  38% - acc: 0.7422 - loss: 1.7160 - 77.3 sample/sec\n",
      "Global step:  2898 - [===========>------------------]  41% - acc: 0.7734 - loss: 1.6935 - 90.9 sample/sec\n",
      "Global step:  2908 - [============>-----------------]  43% - acc: 0.7656 - loss: 1.7071 - 39.8 sample/sec\n",
      "Global step:  2918 - [=============>----------------]  46% - acc: 0.8203 - loss: 1.6367 - 93.7 sample/sec\n",
      "Global step:  2928 - [==============>---------------]  49% - acc: 0.7500 - loss: 1.7055 - 94.6 sample/sec\n",
      "Global step:  2938 - [==============>---------------]  51% - acc: 0.7109 - loss: 1.7510 - 50.4 sample/sec\n",
      "Global step:  2948 - [===============>--------------]  54% - acc: 0.7500 - loss: 1.6887 - 95.6 sample/sec\n",
      "Global step:  2958 - [================>-------------]  56% - acc: 0.8203 - loss: 1.6412 - 31.7 sample/sec\n",
      "Global step:  2968 - [=================>------------]  59% - acc: 0.8203 - loss: 1.6462 - 91.6 sample/sec\n",
      "Global step:  2978 - [=================>------------]  61% - acc: 0.7031 - loss: 1.7565 - 60.6 sample/sec\n",
      "Global step:  2988 - [==================>-----------]  64% - acc: 0.7188 - loss: 1.7412 - 35.2 sample/sec\n",
      "Global step:  2998 - [===================>----------]  66% - acc: 0.7109 - loss: 1.7404 - 71.6 sample/sec\n",
      "Global step:  3008 - [====================>---------]  69% - acc: 0.7109 - loss: 1.7506 - 94.2 sample/sec\n",
      "Global step:  3018 - [====================>---------]  72% - acc: 0.7188 - loss: 1.7376 - 37.7 sample/sec\n",
      "Global step:  3028 - [=====================>--------]  74% - acc: 0.7188 - loss: 1.7388 - 93.1 sample/sec\n",
      "Global step:  3038 - [======================>-------]  77% - acc: 0.7500 - loss: 1.7036 - 38.3 sample/sec\n",
      "Global step:  3048 - [======================>-------]  79% - acc: 0.7109 - loss: 1.7426 - 95.0 sample/sec\n",
      "Global step:  3058 - [=======================>------]  82% - acc: 0.6953 - loss: 1.7781 - 40.3 sample/sec\n",
      "Global step:  3068 - [========================>-----]  84% - acc: 0.8203 - loss: 1.6450 - 58.7 sample/sec\n",
      "Global step:  3078 - [=========================>----]  87% - acc: 0.7344 - loss: 1.7122 - 92.0 sample/sec\n",
      "Global step:  3088 - [==========================>---]  90% - acc: 0.7500 - loss: 1.7204 - 40.8 sample/sec\n",
      "Global step:  3098 - [==========================>---]  92% - acc: 0.7891 - loss: 1.6731 - 95.3 sample/sec\n",
      "Global step:  3108 - [===========================>--]  95% - acc: 0.6875 - loss: 1.7573 - 40.9 sample/sec\n",
      "Global step:  3118 - [============================>-]  97% - acc: 0.8125 - loss: 1.6555 - 97.5 sample/sec\n",
      "Global step:  3128 - [=============================>] 100% - acc: 0.7625 - loss: 1.6917 - 59.7 sample/sec\n",
      "\n",
      "Epoch 8 - accuracy: 69.98% (6998/10000) - time: 00:14:57.14\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 9/60\n",
      "\n",
      "Global step:  3129 - [>-----------------------------]   0% - acc: 0.7812 - loss: 1.6897 - 97.0 sample/sec\n",
      "Global step:  3139 - [>-----------------------------]   3% - acc: 0.8047 - loss: 1.6694 - 52.7 sample/sec\n",
      "Global step:  3149 - [=>----------------------------]   5% - acc: 0.8594 - loss: 1.6078 - 94.2 sample/sec\n",
      "Global step:  3159 - [==>---------------------------]   8% - acc: 0.7969 - loss: 1.6647 - 45.0 sample/sec\n",
      "Global step:  3169 - [==>---------------------------]  10% - acc: 0.7734 - loss: 1.6884 - 95.4 sample/sec\n",
      "Global step:  3179 - [===>--------------------------]  13% - acc: 0.7969 - loss: 1.6643 - 38.8 sample/sec\n",
      "Global step:  3189 - [====>-------------------------]  15% - acc: 0.7969 - loss: 1.6790 - 96.2 sample/sec\n",
      "Global step:  3199 - [=====>------------------------]  18% - acc: 0.7500 - loss: 1.7290 - 37.5 sample/sec\n",
      "Global step:  3209 - [=====>------------------------]  20% - acc: 0.7969 - loss: 1.6496 - 96.5 sample/sec\n",
      "Global step:  3219 - [======>-----------------------]  23% - acc: 0.8281 - loss: 1.6314 - 35.4 sample/sec\n",
      "Global step:  3229 - [=======>----------------------]  26% - acc: 0.7812 - loss: 1.6689 - 95.1 sample/sec\n",
      "Global step:  3239 - [========>---------------------]  28% - acc: 0.7500 - loss: 1.7104 - 30.3 sample/sec\n",
      "Global step:  3249 - [========>---------------------]  31% - acc: 0.7578 - loss: 1.6969 - 81.4 sample/sec\n",
      "Global step:  3259 - [=========>--------------------]  33% - acc: 0.7109 - loss: 1.7592 - 97.2 sample/sec\n",
      "Global step:  3269 - [==========>-------------------]  36% - acc: 0.7188 - loss: 1.7275 - 30.0 sample/sec\n",
      "Global step:  3279 - [===========>------------------]  38% - acc: 0.7422 - loss: 1.7088 - 42.5 sample/sec\n",
      "Global step:  3289 - [===========>------------------]  41% - acc: 0.7812 - loss: 1.6827 - 74.5 sample/sec\n",
      "Global step:  3299 - [============>-----------------]  43% - acc: 0.7344 - loss: 1.7135 - 69.7 sample/sec\n",
      "Global step:  3309 - [=============>----------------]  46% - acc: 0.8125 - loss: 1.6439 - 28.3 sample/sec\n",
      "Global step:  3319 - [==============>---------------]  49% - acc: 0.7422 - loss: 1.7042 - 94.2 sample/sec\n",
      "Global step:  3329 - [==============>---------------]  51% - acc: 0.7266 - loss: 1.7337 - 98.3 sample/sec\n",
      "Global step:  3339 - [===============>--------------]  54% - acc: 0.7812 - loss: 1.6774 - 43.3 sample/sec\n",
      "Global step:  3349 - [================>-------------]  56% - acc: 0.8359 - loss: 1.6296 - 92.3 sample/sec\n",
      "Global step:  3359 - [=================>------------]  59% - acc: 0.7812 - loss: 1.6763 - 33.1 sample/sec\n",
      "Global step:  3369 - [=================>------------]  61% - acc: 0.7188 - loss: 1.7488 - 92.6 sample/sec\n",
      "Global step:  3379 - [==================>-----------]  64% - acc: 0.7344 - loss: 1.7186 - 48.3 sample/sec\n",
      "Global step:  3389 - [===================>----------]  66% - acc: 0.7266 - loss: 1.7332 - 93.1 sample/sec\n",
      "Global step:  3399 - [====================>---------]  69% - acc: 0.7109 - loss: 1.7452 - 58.9 sample/sec\n",
      "Global step:  3409 - [====================>---------]  72% - acc: 0.7188 - loss: 1.7301 - 94.2 sample/sec\n",
      "Global step:  3419 - [=====================>--------]  74% - acc: 0.7500 - loss: 1.7147 - 55.9 sample/sec\n",
      "Global step:  3429 - [======================>-------]  77% - acc: 0.7656 - loss: 1.6831 - 93.8 sample/sec\n",
      "Global step:  3439 - [======================>-------]  79% - acc: 0.7109 - loss: 1.7553 - 74.5 sample/sec\n",
      "Global step:  3449 - [=======================>------]  82% - acc: 0.7266 - loss: 1.7319 - 93.8 sample/sec\n",
      "Global step:  3459 - [========================>-----]  84% - acc: 0.8438 - loss: 1.6223 - 83.3 sample/sec\n",
      "Global step:  3469 - [=========================>----]  87% - acc: 0.7891 - loss: 1.6672 - 50.6 sample/sec\n",
      "Global step:  3479 - [==========================>---]  90% - acc: 0.7188 - loss: 1.7491 - 92.7 sample/sec\n",
      "Global step:  3489 - [==========================>---]  92% - acc: 0.7891 - loss: 1.6712 - 69.3 sample/sec\n",
      "Global step:  3499 - [===========================>--]  95% - acc: 0.7500 - loss: 1.7051 - 30.7 sample/sec\n",
      "Global step:  3509 - [============================>-]  97% - acc: 0.7891 - loss: 1.6734 - 46.7 sample/sec\n",
      "Global step:  3519 - [=============================>] 100% - acc: 0.8000 - loss: 1.6596 - 48.5 sample/sec\n",
      "\n",
      "Epoch 9 - accuracy: 72.35% (7235/10000) - time: 00:14:44.31\n",
      "This epoch receive better accuracy: 72.35 > 70.15. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 10/60\n",
      "\n",
      "Global step:  3520 - [>-----------------------------]   0% - acc: 0.8281 - loss: 1.6314 - 95.1 sample/sec\n",
      "Global step:  3530 - [>-----------------------------]   3% - acc: 0.8047 - loss: 1.6532 - 94.2 sample/sec\n",
      "Global step:  3540 - [=>----------------------------]   5% - acc: 0.8516 - loss: 1.6154 - 41.4 sample/sec\n",
      "Global step:  3550 - [==>---------------------------]   8% - acc: 0.8359 - loss: 1.6378 - 88.4 sample/sec\n",
      "Global step:  3560 - [==>---------------------------]  10% - acc: 0.7891 - loss: 1.6763 - 61.4 sample/sec\n",
      "Global step:  3570 - [===>--------------------------]  13% - acc: 0.7266 - loss: 1.7192 - 95.3 sample/sec\n",
      "Global step:  3580 - [====>-------------------------]  15% - acc: 0.7812 - loss: 1.6829 - 59.6 sample/sec\n",
      "Global step:  3590 - [=====>------------------------]  18% - acc: 0.7656 - loss: 1.7000 - 92.0 sample/sec\n",
      "Global step:  3600 - [=====>------------------------]  20% - acc: 0.7734 - loss: 1.6886 - 59.6 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  3610 - [======>-----------------------]  23% - acc: 0.8516 - loss: 1.6091 - 94.2 sample/sec\n",
      "Global step:  3620 - [=======>----------------------]  26% - acc: 0.8359 - loss: 1.6297 - 97.5 sample/sec\n",
      "Global step:  3630 - [========>---------------------]  28% - acc: 0.7578 - loss: 1.7042 - 72.2 sample/sec\n",
      "Global step:  3640 - [========>---------------------]  31% - acc: 0.8125 - loss: 1.6578 - 97.3 sample/sec\n",
      "Global step:  3650 - [=========>--------------------]  33% - acc: 0.7734 - loss: 1.6932 - 66.7 sample/sec\n",
      "Global step:  3660 - [==========>-------------------]  36% - acc: 0.7500 - loss: 1.7097 - 97.5 sample/sec\n",
      "Global step:  3670 - [===========>------------------]  38% - acc: 0.7656 - loss: 1.6977 - 91.0 sample/sec\n",
      "Global step:  3680 - [===========>------------------]  41% - acc: 0.7578 - loss: 1.6996 - 61.3 sample/sec\n",
      "Global step:  3690 - [============>-----------------]  43% - acc: 0.7734 - loss: 1.6831 - 55.0 sample/sec\n",
      "Global step:  3700 - [=============>----------------]  46% - acc: 0.8125 - loss: 1.6588 - 71.2 sample/sec\n",
      "Global step:  3710 - [==============>---------------]  49% - acc: 0.7578 - loss: 1.6992 - 89.1 sample/sec\n",
      "Global step:  3720 - [==============>---------------]  51% - acc: 0.7969 - loss: 1.6810 - 81.9 sample/sec\n",
      "Global step:  3730 - [===============>--------------]  54% - acc: 0.7969 - loss: 1.6579 - 70.7 sample/sec\n",
      "Global step:  3740 - [================>-------------]  56% - acc: 0.8438 - loss: 1.6207 - 54.2 sample/sec\n",
      "Global step:  3750 - [=================>------------]  59% - acc: 0.7969 - loss: 1.6636 - 89.7 sample/sec\n",
      "Global step:  3760 - [=================>------------]  61% - acc: 0.7656 - loss: 1.6968 - 95.0 sample/sec\n",
      "Global step:  3770 - [==================>-----------]  64% - acc: 0.7344 - loss: 1.7222 - 33.2 sample/sec\n",
      "Global step:  3780 - [===================>----------]  66% - acc: 0.7500 - loss: 1.7067 - 90.0 sample/sec\n",
      "Global step:  3790 - [====================>---------]  69% - acc: 0.7734 - loss: 1.6932 - 31.9 sample/sec\n",
      "Global step:  3800 - [====================>---------]  72% - acc: 0.7812 - loss: 1.6773 - 91.8 sample/sec\n",
      "Global step:  3810 - [=====================>--------]  74% - acc: 0.7969 - loss: 1.6777 - 95.0 sample/sec\n",
      "Global step:  3820 - [======================>-------]  77% - acc: 0.8125 - loss: 1.6496 - 94.9 sample/sec\n",
      "Global step:  3830 - [======================>-------]  79% - acc: 0.7344 - loss: 1.7145 - 56.7 sample/sec\n",
      "Global step:  3840 - [=======================>------]  82% - acc: 0.7812 - loss: 1.6844 - 75.8 sample/sec\n",
      "Global step:  3850 - [========================>-----]  84% - acc: 0.8828 - loss: 1.5858 - 96.7 sample/sec\n",
      "Global step:  3860 - [=========================>----]  87% - acc: 0.8125 - loss: 1.6562 - 43.9 sample/sec\n",
      "Global step:  3870 - [==========================>---]  90% - acc: 0.8047 - loss: 1.6671 - 74.1 sample/sec\n",
      "Global step:  3880 - [==========================>---]  92% - acc: 0.8203 - loss: 1.6401 - 61.8 sample/sec\n",
      "Global step:  3890 - [===========================>--]  95% - acc: 0.7734 - loss: 1.6841 - 34.8 sample/sec\n",
      "Global step:  3900 - [============================>-]  97% - acc: 0.8438 - loss: 1.6193 - 90.8 sample/sec\n",
      "Global step:  3910 - [=============================>] 100% - acc: 0.7875 - loss: 1.6785 - 54.7 sample/sec\n",
      "\n",
      "Epoch 10 - accuracy: 73.83% (7383/10000) - time: 00:14:17.55\n",
      "This epoch receive better accuracy: 73.83 > 72.35. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 11/60\n",
      "\n",
      "Global step:  3911 - [>-----------------------------]   0% - acc: 0.8594 - loss: 1.6073 - 70.6 sample/sec\n",
      "Global step:  3921 - [>-----------------------------]   3% - acc: 0.7969 - loss: 1.6552 - 28.5 sample/sec\n",
      "Global step:  3931 - [=>----------------------------]   5% - acc: 0.8750 - loss: 1.5905 - 35.1 sample/sec\n",
      "Global step:  3941 - [==>---------------------------]   8% - acc: 0.8125 - loss: 1.6417 - 94.2 sample/sec\n",
      "Global step:  3951 - [==>---------------------------]  10% - acc: 0.7812 - loss: 1.6613 - 47.5 sample/sec\n",
      "Global step:  3961 - [===>--------------------------]  13% - acc: 0.7578 - loss: 1.7048 - 95.3 sample/sec\n",
      "Global step:  3971 - [====>-------------------------]  15% - acc: 0.7734 - loss: 1.6860 - 47.0 sample/sec\n",
      "Global step:  3981 - [=====>------------------------]  18% - acc: 0.7656 - loss: 1.6788 - 91.0 sample/sec\n",
      "Global step:  3991 - [=====>------------------------]  20% - acc: 0.8047 - loss: 1.6569 - 61.5 sample/sec\n",
      "Global step:  4001 - [======>-----------------------]  23% - acc: 0.8516 - loss: 1.6134 - 34.2 sample/sec\n",
      "Global step:  4011 - [=======>----------------------]  26% - acc: 0.8203 - loss: 1.6400 - 33.6 sample/sec\n",
      "Global step:  4021 - [========>---------------------]  28% - acc: 0.8047 - loss: 1.6732 - 94.3 sample/sec\n",
      "Global step:  4031 - [========>---------------------]  31% - acc: 0.8359 - loss: 1.6320 - 97.9 sample/sec\n",
      "Global step:  4041 - [=========>--------------------]  33% - acc: 0.7578 - loss: 1.7097 - 77.3 sample/sec\n",
      "Global step:  4051 - [==========>-------------------]  36% - acc: 0.7812 - loss: 1.6905 - 93.9 sample/sec\n",
      "Global step:  4061 - [===========>------------------]  38% - acc: 0.7969 - loss: 1.6691 - 35.3 sample/sec\n",
      "Global step:  4071 - [===========>------------------]  41% - acc: 0.8047 - loss: 1.6409 - 57.3 sample/sec\n",
      "Global step:  4081 - [============>-----------------]  43% - acc: 0.7891 - loss: 1.6684 - 92.7 sample/sec\n",
      "Global step:  4091 - [=============>----------------]  46% - acc: 0.8203 - loss: 1.6370 - 66.3 sample/sec\n",
      "Global step:  4101 - [==============>---------------]  49% - acc: 0.8203 - loss: 1.6424 - 92.9 sample/sec\n",
      "Global step:  4111 - [==============>---------------]  51% - acc: 0.7422 - loss: 1.7080 - 94.2 sample/sec\n",
      "Global step:  4121 - [===============>--------------]  54% - acc: 0.8047 - loss: 1.6629 - 33.8 sample/sec\n",
      "Global step:  4131 - [================>-------------]  56% - acc: 0.8281 - loss: 1.6300 - 90.8 sample/sec\n",
      "Global step:  4141 - [=================>------------]  59% - acc: 0.8594 - loss: 1.6028 - 47.0 sample/sec\n",
      "Global step:  4151 - [=================>------------]  61% - acc: 0.7422 - loss: 1.7150 - 91.6 sample/sec\n",
      "Global step:  4161 - [==================>-----------]  64% - acc: 0.7266 - loss: 1.7349 - 94.5 sample/sec\n",
      "Global step:  4171 - [===================>----------]  66% - acc: 0.7266 - loss: 1.7397 - 33.5 sample/sec\n",
      "Global step:  4181 - [====================>---------]  69% - acc: 0.7422 - loss: 1.7300 - 94.2 sample/sec\n",
      "Global step:  4191 - [====================>---------]  72% - acc: 0.8359 - loss: 1.6279 - 41.3 sample/sec\n",
      "Global step:  4201 - [=====================>--------]  74% - acc: 0.8125 - loss: 1.6558 - 92.3 sample/sec\n",
      "Global step:  4211 - [======================>-------]  77% - acc: 0.8125 - loss: 1.6452 - 97.3 sample/sec\n",
      "Global step:  4221 - [======================>-------]  79% - acc: 0.7266 - loss: 1.7389 - 86.9 sample/sec\n",
      "Global step:  4231 - [=======================>------]  82% - acc: 0.7656 - loss: 1.7020 - 55.7 sample/sec\n",
      "Global step:  4241 - [========================>-----]  84% - acc: 0.8672 - loss: 1.5965 - 57.7 sample/sec\n",
      "Global step:  4251 - [=========================>----]  87% - acc: 0.8125 - loss: 1.6444 - 77.3 sample/sec\n",
      "Global step:  4261 - [==========================>---]  90% - acc: 0.7812 - loss: 1.6757 - 53.0 sample/sec\n",
      "Global step:  4271 - [==========================>---]  92% - acc: 0.7812 - loss: 1.6811 - 68.5 sample/sec\n",
      "Global step:  4281 - [===========================>--]  95% - acc: 0.8203 - loss: 1.6372 - 89.8 sample/sec\n",
      "Global step:  4291 - [============================>-]  97% - acc: 0.8750 - loss: 1.5905 - 88.6 sample/sec\n",
      "Global step:  4301 - [=============================>] 100% - acc: 0.8250 - loss: 1.6346 - 80.8 sample/sec\n",
      "\n",
      "Epoch 11 - accuracy: 75.18% (7518/10000) - time: 00:14:26.71\n",
      "This epoch receive better accuracy: 75.18 > 73.83. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 12/60\n",
      "\n",
      "Global step:  4302 - [>-----------------------------]   0% - acc: 0.8438 - loss: 1.6133 - 53.0 sample/sec\n",
      "Global step:  4312 - [>-----------------------------]   3% - acc: 0.8359 - loss: 1.6325 - 54.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  4322 - [=>----------------------------]   5% - acc: 0.8672 - loss: 1.5952 - 60.6 sample/sec\n",
      "Global step:  4332 - [==>---------------------------]   8% - acc: 0.8047 - loss: 1.6542 - 74.6 sample/sec\n",
      "Global step:  4342 - [==>---------------------------]  10% - acc: 0.8125 - loss: 1.6469 - 27.9 sample/sec\n",
      "Global step:  4352 - [===>--------------------------]  13% - acc: 0.8047 - loss: 1.6579 - 64.3 sample/sec\n",
      "Global step:  4362 - [====>-------------------------]  15% - acc: 0.8047 - loss: 1.6519 - 44.0 sample/sec\n",
      "Global step:  4372 - [=====>------------------------]  18% - acc: 0.8281 - loss: 1.6467 - 35.2 sample/sec\n",
      "Global step:  4382 - [=====>------------------------]  20% - acc: 0.8438 - loss: 1.6204 - 74.1 sample/sec\n",
      "Global step:  4392 - [======>-----------------------]  23% - acc: 0.8984 - loss: 1.5679 - 34.4 sample/sec\n",
      "Global step:  4402 - [=======>----------------------]  26% - acc: 0.8516 - loss: 1.6071 - 58.8 sample/sec\n",
      "Global step:  4412 - [========>---------------------]  28% - acc: 0.8516 - loss: 1.6157 - 27.0 sample/sec\n",
      "Global step:  4422 - [========>---------------------]  31% - acc: 0.8203 - loss: 1.6398 - 52.5 sample/sec\n",
      "Global step:  4432 - [=========>--------------------]  33% - acc: 0.7891 - loss: 1.6728 - 69.2 sample/sec\n",
      "Global step:  4442 - [==========>-------------------]  36% - acc: 0.7891 - loss: 1.6650 - 60.9 sample/sec\n",
      "Global step:  4452 - [===========>------------------]  38% - acc: 0.8281 - loss: 1.6318 - 84.4 sample/sec\n",
      "Global step:  4462 - [===========>------------------]  41% - acc: 0.8438 - loss: 1.6178 - 23.9 sample/sec\n",
      "Global step:  4472 - [============>-----------------]  43% - acc: 0.7812 - loss: 1.6821 - 25.5 sample/sec\n",
      "Global step:  4482 - [=============>----------------]  46% - acc: 0.8281 - loss: 1.6341 - 73.8 sample/sec\n",
      "Global step:  4492 - [==============>---------------]  49% - acc: 0.8359 - loss: 1.6344 - 75.6 sample/sec\n",
      "Global step:  4502 - [==============>---------------]  51% - acc: 0.7422 - loss: 1.7160 - 84.3 sample/sec\n",
      "Global step:  4512 - [===============>--------------]  54% - acc: 0.8047 - loss: 1.6689 - 46.1 sample/sec\n",
      "Global step:  4522 - [================>-------------]  56% - acc: 0.8750 - loss: 1.5921 - 61.7 sample/sec\n",
      "Global step:  4532 - [=================>------------]  59% - acc: 0.8359 - loss: 1.6256 - 25.4 sample/sec\n",
      "Global step:  4542 - [=================>------------]  61% - acc: 0.7734 - loss: 1.6884 - 22.7 sample/sec\n",
      "Global step:  4552 - [==================>-----------]  64% - acc: 0.7500 - loss: 1.7160 - 41.6 sample/sec\n",
      "Global step:  4562 - [===================>----------]  66% - acc: 0.7656 - loss: 1.6925 - 29.8 sample/sec\n",
      "Global step:  4572 - [====================>---------]  69% - acc: 0.7578 - loss: 1.7023 - 76.9 sample/sec\n",
      "Global step:  4582 - [====================>---------]  72% - acc: 0.8281 - loss: 1.6246 - 62.7 sample/sec\n",
      "Global step:  4592 - [=====================>--------]  74% - acc: 0.7891 - loss: 1.6690 - 34.6 sample/sec\n",
      "Global step:  4602 - [======================>-------]  77% - acc: 0.8125 - loss: 1.6400 - 63.3 sample/sec\n",
      "Global step:  4612 - [======================>-------]  79% - acc: 0.7578 - loss: 1.7026 - 67.1 sample/sec\n",
      "Global step:  4622 - [=======================>------]  82% - acc: 0.7969 - loss: 1.6680 - 69.3 sample/sec\n",
      "Global step:  4632 - [========================>-----]  84% - acc: 0.8594 - loss: 1.5979 - 26.5 sample/sec\n",
      "Global step:  4642 - [=========================>----]  87% - acc: 0.7969 - loss: 1.6538 - 24.6 sample/sec\n",
      "Global step:  4652 - [==========================>---]  90% - acc: 0.7969 - loss: 1.6650 - 26.3 sample/sec\n",
      "Global step:  4662 - [==========================>---]  92% - acc: 0.8281 - loss: 1.6243 - 45.0 sample/sec\n",
      "Global step:  4672 - [===========================>--]  95% - acc: 0.7734 - loss: 1.6837 - 73.3 sample/sec\n",
      "Global step:  4682 - [============================>-]  97% - acc: 0.8672 - loss: 1.5929 - 56.3 sample/sec\n",
      "Global step:  4692 - [=============================>] 100% - acc: 0.8125 - loss: 1.6477 - 94.4 sample/sec\n",
      "\n",
      "Epoch 12 - accuracy: 73.25% (7325/10000) - time: 00:20:31.59\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 13/60\n",
      "\n",
      "Global step:  4693 - [>-----------------------------]   0% - acc: 0.8750 - loss: 1.5923 - 87.6 sample/sec\n",
      "Global step:  4703 - [>-----------------------------]   3% - acc: 0.8516 - loss: 1.6265 - 35.6 sample/sec\n",
      "Global step:  4713 - [=>----------------------------]   5% - acc: 0.8750 - loss: 1.5863 - 70.6 sample/sec\n",
      "Global step:  4723 - [==>---------------------------]   8% - acc: 0.8359 - loss: 1.6321 - 39.4 sample/sec\n",
      "Global step:  4733 - [==>---------------------------]  10% - acc: 0.8047 - loss: 1.6556 - 87.7 sample/sec\n",
      "Global step:  4743 - [===>--------------------------]  13% - acc: 0.7891 - loss: 1.6804 - 90.5 sample/sec\n",
      "Global step:  4753 - [====>-------------------------]  15% - acc: 0.8047 - loss: 1.6539 - 36.2 sample/sec\n",
      "Global step:  4763 - [=====>------------------------]  18% - acc: 0.7891 - loss: 1.6627 - 84.2 sample/sec\n",
      "Global step:  4773 - [=====>------------------------]  20% - acc: 0.8359 - loss: 1.6175 - 33.0 sample/sec\n",
      "Global step:  4783 - [======>-----------------------]  23% - acc: 0.8125 - loss: 1.6530 - 29.5 sample/sec\n",
      "Global step:  4793 - [=======>----------------------]  26% - acc: 0.8672 - loss: 1.5951 - 70.9 sample/sec\n",
      "Global step:  4803 - [========>---------------------]  28% - acc: 0.8281 - loss: 1.6359 - 90.7 sample/sec\n",
      "Global step:  4813 - [========>---------------------]  31% - acc: 0.8750 - loss: 1.5859 - 95.6 sample/sec\n",
      "Global step:  4823 - [=========>--------------------]  33% - acc: 0.7812 - loss: 1.6799 - 52.6 sample/sec\n",
      "Global step:  4833 - [==========>-------------------]  36% - acc: 0.8047 - loss: 1.6561 - 51.8 sample/sec\n",
      "Global step:  4843 - [===========>------------------]  38% - acc: 0.8359 - loss: 1.6373 - 85.2 sample/sec\n",
      "Global step:  4853 - [===========>------------------]  41% - acc: 0.8672 - loss: 1.5948 - 75.5 sample/sec\n",
      "Global step:  4863 - [============>-----------------]  43% - acc: 0.8125 - loss: 1.6519 - 66.8 sample/sec\n",
      "Global step:  4873 - [=============>----------------]  46% - acc: 0.8359 - loss: 1.6308 - 28.6 sample/sec\n",
      "Global step:  4883 - [==============>---------------]  49% - acc: 0.7891 - loss: 1.6720 - 28.0 sample/sec\n",
      "Global step:  4893 - [==============>---------------]  51% - acc: 0.7500 - loss: 1.7066 - 58.3 sample/sec\n",
      "Global step:  4903 - [===============>--------------]  54% - acc: 0.8438 - loss: 1.6247 - 54.6 sample/sec\n",
      "Global step:  4913 - [================>-------------]  56% - acc: 0.8750 - loss: 1.5960 - 33.0 sample/sec\n",
      "Global step:  4923 - [=================>------------]  59% - acc: 0.8516 - loss: 1.6043 - 57.6 sample/sec\n",
      "Global step:  4933 - [=================>------------]  61% - acc: 0.7578 - loss: 1.7161 - 85.2 sample/sec\n",
      "Global step:  4943 - [==================>-----------]  64% - acc: 0.7734 - loss: 1.6915 - 70.1 sample/sec\n",
      "Global step:  4953 - [===================>----------]  66% - acc: 0.7734 - loss: 1.6860 - 26.8 sample/sec\n",
      "Global step:  4963 - [====================>---------]  69% - acc: 0.8359 - loss: 1.6394 - 52.1 sample/sec\n",
      "Global step:  4973 - [====================>---------]  72% - acc: 0.8906 - loss: 1.5847 - 88.1 sample/sec\n",
      "Global step:  4983 - [=====================>--------]  74% - acc: 0.8438 - loss: 1.6216 - 88.5 sample/sec\n",
      "Global step:  4993 - [======================>-------]  77% - acc: 0.8203 - loss: 1.6418 - 42.4 sample/sec\n",
      "Global step:  5003 - [======================>-------]  79% - acc: 0.7891 - loss: 1.6737 - 30.0 sample/sec\n",
      "Global step:  5013 - [=======================>------]  82% - acc: 0.7344 - loss: 1.7183 - 88.2 sample/sec\n",
      "Global step:  5023 - [========================>-----]  84% - acc: 0.8281 - loss: 1.6231 - 31.2 sample/sec\n",
      "Global step:  5033 - [=========================>----]  87% - acc: 0.8047 - loss: 1.6624 - 63.8 sample/sec\n",
      "Global step:  5043 - [==========================>---]  90% - acc: 0.8047 - loss: 1.6530 - 23.7 sample/sec\n",
      "Global step:  5053 - [==========================>---]  92% - acc: 0.8359 - loss: 1.6186 - 58.1 sample/sec\n",
      "Global step:  5063 - [===========================>--]  95% - acc: 0.7812 - loss: 1.6807 - 24.2 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  5073 - [============================>-]  97% - acc: 0.8672 - loss: 1.5937 - 71.9 sample/sec\n",
      "Global step:  5083 - [=============================>] 100% - acc: 0.8625 - loss: 1.5884 - 44.2 sample/sec\n",
      "\n",
      "Epoch 13 - accuracy: 75.52% (7552/10000) - time: 00:19:11.51\n",
      "This epoch receive better accuracy: 75.52 > 75.18. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 14/60\n",
      "\n",
      "Global step:  5084 - [>-----------------------------]   0% - acc: 0.9062 - loss: 1.5560 - 31.5 sample/sec\n",
      "Global step:  5094 - [>-----------------------------]   3% - acc: 0.7812 - loss: 1.6698 - 35.0 sample/sec\n",
      "Global step:  5104 - [=>----------------------------]   5% - acc: 0.8906 - loss: 1.5749 - 48.6 sample/sec\n",
      "Global step:  5114 - [==>---------------------------]   8% - acc: 0.8516 - loss: 1.6153 - 76.5 sample/sec\n",
      "Global step:  5124 - [==>---------------------------]  10% - acc: 0.8438 - loss: 1.6138 - 65.0 sample/sec\n",
      "Global step:  5134 - [===>--------------------------]  13% - acc: 0.8047 - loss: 1.6536 - 37.8 sample/sec\n",
      "Global step:  5144 - [====>-------------------------]  15% - acc: 0.8516 - loss: 1.6045 - 37.4 sample/sec\n",
      "Global step:  5154 - [=====>------------------------]  18% - acc: 0.8438 - loss: 1.6140 - 27.9 sample/sec\n",
      "Global step:  5164 - [=====>------------------------]  20% - acc: 0.8672 - loss: 1.5950 - 76.7 sample/sec\n",
      "Global step:  5174 - [======>-----------------------]  23% - acc: 0.8984 - loss: 1.5688 - 59.6 sample/sec\n",
      "Global step:  5184 - [=======>----------------------]  26% - acc: 0.8906 - loss: 1.5761 - 47.6 sample/sec\n",
      "Global step:  5194 - [========>---------------------]  28% - acc: 0.8047 - loss: 1.6457 - 90.9 sample/sec\n",
      "Global step:  5204 - [========>---------------------]  31% - acc: 0.8516 - loss: 1.6061 - 57.6 sample/sec\n",
      "Global step:  5214 - [=========>--------------------]  33% - acc: 0.8438 - loss: 1.6192 - 64.0 sample/sec\n",
      "Global step:  5224 - [==========>-------------------]  36% - acc: 0.7812 - loss: 1.6793 - 87.5 sample/sec\n",
      "Global step:  5234 - [===========>------------------]  38% - acc: 0.8281 - loss: 1.6378 - 74.7 sample/sec\n",
      "Global step:  5244 - [===========>------------------]  41% - acc: 0.8438 - loss: 1.6213 - 35.5 sample/sec\n",
      "Global step:  5254 - [============>-----------------]  43% - acc: 0.8203 - loss: 1.6377 - 78.0 sample/sec\n",
      "Global step:  5264 - [=============>----------------]  46% - acc: 0.8047 - loss: 1.6436 - 87.1 sample/sec\n",
      "Global step:  5274 - [==============>---------------]  49% - acc: 0.8281 - loss: 1.6301 - 95.7 sample/sec\n",
      "Global step:  5284 - [==============>---------------]  51% - acc: 0.7734 - loss: 1.6984 - 33.1 sample/sec\n",
      "Global step:  5294 - [===============>--------------]  54% - acc: 0.8594 - loss: 1.6136 - 93.1 sample/sec\n",
      "Global step:  5304 - [================>-------------]  56% - acc: 0.8203 - loss: 1.6276 - 60.0 sample/sec\n",
      "Global step:  5314 - [=================>------------]  59% - acc: 0.8516 - loss: 1.6105 - 52.0 sample/sec\n",
      "Global step:  5324 - [=================>------------]  61% - acc: 0.7734 - loss: 1.6931 - 90.6 sample/sec\n",
      "Global step:  5334 - [==================>-----------]  64% - acc: 0.7812 - loss: 1.6781 - 68.6 sample/sec\n",
      "Global step:  5344 - [===================>----------]  66% - acc: 0.8281 - loss: 1.6321 - 70.1 sample/sec\n",
      "Global step:  5354 - [====================>---------]  69% - acc: 0.8203 - loss: 1.6415 - 27.4 sample/sec\n",
      "Global step:  5364 - [====================>---------]  72% - acc: 0.8516 - loss: 1.6042 - 74.9 sample/sec\n",
      "Global step:  5374 - [=====================>--------]  74% - acc: 0.8672 - loss: 1.5916 - 29.8 sample/sec\n",
      "Global step:  5384 - [======================>-------]  77% - acc: 0.8359 - loss: 1.6245 - 72.8 sample/sec\n",
      "Global step:  5394 - [======================>-------]  79% - acc: 0.8047 - loss: 1.6605 - 26.0 sample/sec\n",
      "Global step:  5404 - [=======================>------]  82% - acc: 0.8359 - loss: 1.6380 - 62.6 sample/sec\n",
      "Global step:  5414 - [========================>-----]  84% - acc: 0.9297 - loss: 1.5344 - 32.5 sample/sec\n",
      "Global step:  5424 - [=========================>----]  87% - acc: 0.8594 - loss: 1.6034 - 89.4 sample/sec\n",
      "Global step:  5434 - [==========================>---]  90% - acc: 0.8594 - loss: 1.6139 - 87.3 sample/sec\n",
      "Global step:  5444 - [==========================>---]  92% - acc: 0.8438 - loss: 1.6075 - 31.7 sample/sec\n",
      "Global step:  5454 - [===========================>--]  95% - acc: 0.8594 - loss: 1.6026 - 90.7 sample/sec\n",
      "Global step:  5464 - [============================>-]  97% - acc: 0.8750 - loss: 1.5868 - 38.6 sample/sec\n",
      "Global step:  5474 - [=============================>] 100% - acc: 0.8875 - loss: 1.5809 - 46.3 sample/sec\n",
      "\n",
      "Epoch 14 - accuracy: 75.77% (7577/10000) - time: 00:17:57.90\n",
      "This epoch receive better accuracy: 75.77 > 75.52. Saving session...\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 15/60\n",
      "\n",
      "Global step:  5475 - [>-----------------------------]   0% - acc: 0.9297 - loss: 1.5349 - 96.0 sample/sec\n",
      "Global step:  5485 - [>-----------------------------]   3% - acc: 0.8359 - loss: 1.6228 - 93.6 sample/sec\n",
      "Global step:  5495 - [=>----------------------------]   5% - acc: 0.8906 - loss: 1.5766 - 25.5 sample/sec\n",
      "Global step:  5505 - [==>---------------------------]   8% - acc: 0.8281 - loss: 1.6311 - 77.3 sample/sec\n",
      "Global step:  5515 - [==>---------------------------]  10% - acc: 0.8203 - loss: 1.6401 - 91.0 sample/sec\n",
      "Global step:  5525 - [===>--------------------------]  13% - acc: 0.8203 - loss: 1.6486 - 59.3 sample/sec\n",
      "Global step:  5535 - [====>-------------------------]  15% - acc: 0.8125 - loss: 1.6389 - 46.7 sample/sec\n",
      "Global step:  5545 - [=====>------------------------]  18% - acc: 0.8594 - loss: 1.6104 - 89.0 sample/sec\n",
      "Global step:  5555 - [=====>------------------------]  20% - acc: 0.9062 - loss: 1.5609 - 94.1 sample/sec\n",
      "Global step:  5565 - [======>-----------------------]  23% - acc: 0.8828 - loss: 1.5796 - 34.8 sample/sec\n",
      "Global step:  5575 - [=======>----------------------]  26% - acc: 0.8672 - loss: 1.5917 - 90.1 sample/sec\n",
      "Global step:  5585 - [========>---------------------]  28% - acc: 0.8750 - loss: 1.5890 - 92.1 sample/sec\n",
      "Global step:  5595 - [========>---------------------]  31% - acc: 0.8359 - loss: 1.6250 - 71.3 sample/sec\n",
      "Global step:  5605 - [=========>--------------------]  33% - acc: 0.8281 - loss: 1.6313 - 61.0 sample/sec\n",
      "Global step:  5615 - [==========>-------------------]  36% - acc: 0.8438 - loss: 1.6133 - 35.7 sample/sec\n",
      "Global step:  5625 - [===========>------------------]  38% - acc: 0.8359 - loss: 1.6302 - 40.2 sample/sec\n",
      "Global step:  5635 - [===========>------------------]  41% - acc: 0.8672 - loss: 1.6011 - 65.1 sample/sec\n",
      "Global step:  5645 - [============>-----------------]  43% - acc: 0.8516 - loss: 1.6126 - 43.7 sample/sec\n",
      "Global step:  5655 - [=============>----------------]  46% - acc: 0.8359 - loss: 1.6216 - 36.7 sample/sec\n",
      "Global step:  5665 - [==============>---------------]  49% - acc: 0.8281 - loss: 1.6289 - 24.1 sample/sec\n",
      "Global step:  5675 - [==============>---------------]  51% - acc: 0.7969 - loss: 1.6595 - 46.1 sample/sec\n",
      "Global step:  5685 - [===============>--------------]  54% - acc: 0.8203 - loss: 1.6189 - 32.8 sample/sec\n",
      "Global step:  5695 - [================>-------------]  56% - acc: 0.8672 - loss: 1.5957 - 55.7 sample/sec\n",
      "Global step:  5705 - [=================>------------]  59% - acc: 0.8828 - loss: 1.5850 - 37.5 sample/sec\n",
      "Global step:  5715 - [=================>------------]  61% - acc: 0.7656 - loss: 1.6975 - 24.9 sample/sec\n",
      "Global step:  5725 - [==================>-----------]  64% - acc: 0.7969 - loss: 1.6641 - 67.7 sample/sec\n",
      "Global step:  5735 - [===================>----------]  66% - acc: 0.8125 - loss: 1.6497 - 35.1 sample/sec\n",
      "Global step:  5745 - [====================>---------]  69% - acc: 0.8047 - loss: 1.6513 - 79.2 sample/sec\n",
      "Global step:  5755 - [====================>---------]  72% - acc: 0.8828 - loss: 1.5768 - 70.5 sample/sec\n",
      "Global step:  5765 - [=====================>--------]  74% - acc: 0.8359 - loss: 1.6223 - 76.8 sample/sec\n",
      "Global step:  5775 - [======================>-------]  77% - acc: 0.8359 - loss: 1.6148 - 74.4 sample/sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global step:  5785 - [======================>-------]  79% - acc: 0.7891 - loss: 1.6693 - 74.0 sample/sec\n",
      "Global step:  5795 - [=======================>------]  82% - acc: 0.8359 - loss: 1.6204 - 45.3 sample/sec\n",
      "Global step:  5805 - [========================>-----]  84% - acc: 0.9141 - loss: 1.5468 - 47.5 sample/sec\n",
      "Global step:  5815 - [=========================>----]  87% - acc: 0.8281 - loss: 1.6279 - 73.6 sample/sec\n",
      "Global step:  5825 - [==========================>---]  90% - acc: 0.8594 - loss: 1.6046 - 75.2 sample/sec\n",
      "Global step:  5835 - [==========================>---]  92% - acc: 0.8438 - loss: 1.6177 - 77.0 sample/sec\n",
      "Global step:  5845 - [===========================>--]  95% - acc: 0.8281 - loss: 1.6311 - 61.3 sample/sec\n",
      "Global step:  5855 - [============================>-]  97% - acc: 0.8828 - loss: 1.5829 - 72.4 sample/sec\n",
      "Global step:  5865 - [=============================>] 100% - acc: 0.8375 - loss: 1.6022 - 42.9 sample/sec\n",
      "\n",
      "Epoch 15 - accuracy: 75.31% (7531/10000) - time: 00:20:51.19\n",
      "###########################################################################################################\n",
      "\n",
      "Epoch: 16/60\n",
      "\n",
      "Global step:  5866 - [>-----------------------------]   0% - acc: 0.8750 - loss: 1.5867 - 23.6 sample/sec\n",
      "Global step:  5876 - [>-----------------------------]   3% - acc: 0.8516 - loss: 1.6045 - 38.1 sample/sec\n",
      "Global step:  5886 - [=>----------------------------]   5% - acc: 0.9062 - loss: 1.5603 - 34.4 sample/sec\n",
      "Global step:  5896 - [==>---------------------------]   8% - acc: 0.8594 - loss: 1.5984 - 38.8 sample/sec\n",
      "Global step:  5906 - [==>---------------------------]  10% - acc: 0.8516 - loss: 1.6022 - 62.7 sample/sec\n",
      "Global step:  5916 - [===>--------------------------]  13% - acc: 0.8516 - loss: 1.6080 - 21.5 sample/sec\n",
      "Global step:  5926 - [====>-------------------------]  15% - acc: 0.8750 - loss: 1.5878 - 22.8 sample/sec\n",
      "Global step:  5936 - [=====>------------------------]  18% - acc: 0.8516 - loss: 1.6177 - 23.7 sample/sec\n",
      "Global step:  5946 - [=====>------------------------]  20% - acc: 0.8984 - loss: 1.5605 - 23.0 sample/sec\n",
      "Global step:  5956 - [======>-----------------------]  23% - acc: 0.8906 - loss: 1.5731 - 25.2 sample/sec\n",
      "Global step:  5966 - [=======>----------------------]  26% - acc: 0.8828 - loss: 1.5814 - 36.1 sample/sec\n",
      "Global step:  5976 - [========>---------------------]  28% - acc: 0.8750 - loss: 1.5916 - 73.6 sample/sec\n",
      "Global step:  5986 - [========>---------------------]  31% - acc: 0.8672 - loss: 1.5944 - 23.8 sample/sec\n",
      "Global step:  5996 - [=========>--------------------]  33% - acc: 0.8516 - loss: 1.6159 - 24.0 sample/sec\n",
      "Global step:  6006 - [==========>-------------------]  36% - acc: 0.8359 - loss: 1.6312 - 55.6 sample/sec\n",
      "Global step:  6016 - [===========>------------------]  38% - acc: 0.8438 - loss: 1.6162 - 25.3 sample/sec\n",
      "Global step:  6026 - [===========>------------------]  41% - acc: 0.9062 - loss: 1.5575 - 29.2 sample/sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a3060b43de24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m \u001b[0mtrain_custom_nn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a3060b43de24>\u001b[0m in \u001b[0;36mtrain_custom_nn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nEpoch: {}/{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtrain_start\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-a3060b43de24>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     62\u001b[0m         i_global, _, batch_loss, batch_acc = sess.run(\n\u001b[0;32m     63\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)})\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\apps\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from data import get_data_set\n",
    "from model import model, lr\n",
    "from time import time\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "train_x, train_y = get_data_set(\"train\")\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "tf.set_random_seed(21)\n",
    "x, y, output, y_pred_cls, global_step, learning_rate = model()\n",
    "global_accuracy = 0\n",
    "epoch_start = 0\n",
    "\n",
    "\n",
    "# PARAMS\n",
    "_BATCH_SIZE = 128\n",
    "_EPOCH = 15\n",
    "_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n",
    "\n",
    "\n",
    "# LOSS AND OPTIMIZER\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                   beta1=0.9,\n",
    "                                   beta2=0.999,\n",
    "                                   epsilon=1e-08).minimize(loss, global_step=global_step)\n",
    "\n",
    "\n",
    "# PREDICTION AND ACCURACY CALCULATION\n",
    "correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "# SAVER\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "train_writer = tf.summary.FileWriter(_SAVE_PATH, sess.graph)\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"\\nTrying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except ValueError:\n",
    "    print(\"\\nFailed to restore checkpoint. Initializing variables instead.\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    global epoch_start\n",
    "    epoch_start = time()\n",
    "    batch_size = int(math.ceil(len(train_x) / _BATCH_SIZE))\n",
    "    i_global = 0\n",
    "\n",
    "    for s in range(batch_size):\n",
    "        batch_xs = train_x[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n",
    "        batch_ys = train_y[s*_BATCH_SIZE: (s+1)*_BATCH_SIZE]\n",
    "\n",
    "        start_time = time()\n",
    "        i_global, _, batch_loss, batch_acc = sess.run(\n",
    "            [global_step, optimizer, loss, accuracy],\n",
    "            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)})\n",
    "        duration = time() - start_time\n",
    "\n",
    "        if s % 10 == 0:\n",
    "            percentage = int(round((s/batch_size)*100))\n",
    "\n",
    "            bar_len = 29\n",
    "            filled_len = int((bar_len*int(percentage))/100)\n",
    "            bar = '=' * filled_len + '>' + '-' * (bar_len - filled_len)\n",
    "\n",
    "            msg = \"Global step: {:>5} - [{}] {:>3}% - acc: {:.4f} - loss: {:.4f} - {:.1f} sample/sec\"\n",
    "            print(msg.format(i_global, bar, percentage, batch_acc, batch_loss, _BATCH_SIZE / duration))\n",
    "\n",
    "    test_and_save(i_global, epoch)\n",
    "\n",
    "\n",
    "def test_and_save(_global_step, epoch):\n",
    "    global global_accuracy\n",
    "    global epoch_start\n",
    "\n",
    "    i = 0\n",
    "    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        predicted_class[i:j] = sess.run(\n",
    "            y_pred_cls,\n",
    "            feed_dict={x: batch_xs, y: batch_ys, learning_rate: lr(epoch)}\n",
    "        )\n",
    "        i = j\n",
    "\n",
    "    correct = (np.argmax(test_y, axis=1) == predicted_class)\n",
    "    acc = correct.mean()*100\n",
    "    correct_numbers = correct.sum()\n",
    "\n",
    "    hours, rem = divmod(time() - epoch_start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    mes = \"\\nEpoch {} - accuracy: {:.2f}% ({}/{}) - time: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "    print(mes.format((epoch+1), acc, correct_numbers, len(test_x), int(hours), int(minutes), seconds))\n",
    "\n",
    "    if global_accuracy != 0 and global_accuracy < acc:\n",
    "\n",
    "        summary = tf.Summary(value=[\n",
    "            tf.Summary.Value(tag=\"Accuracy/test\", simple_value=acc),\n",
    "        ])\n",
    "        train_writer.add_summary(summary, _global_step)\n",
    "\n",
    "        saver.save(sess, save_path=_SAVE_PATH, global_step=_global_step)\n",
    "\n",
    "        mes = \"This epoch receive better accuracy: {:.2f} > {:.2f}. Saving session...\"\n",
    "        print(mes.format(acc, global_accuracy))\n",
    "        global_accuracy = acc\n",
    "\n",
    "    elif global_accuracy == 0:\n",
    "        global_accuracy = acc\n",
    "\n",
    "    print(\"###########################################################################################################\")\n",
    "\n",
    "\n",
    "def train_custom_nn():\n",
    "    train_start = time()\n",
    "\n",
    "    for i in range(_EPOCH):\n",
    "        print(\"\\nEpoch: {}/{}\\n\".format((i+1), _EPOCH))\n",
    "        train(i)\n",
    "\n",
    "    hours, rem = divmod(time() - train_start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    mes = \"Best accuracy pre session: {:.2f}, time: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "    print(mes.format(global_accuracy, int(hours), int(minutes), seconds))\n",
    "\n",
    "\n",
    "train_custom_nn()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from ./tensorboard/cifar-10-v1.0.0/-5474\n",
      "Restored checkpoint from: ./tensorboard/cifar-10-v1.0.0/-5474\n",
      "\n",
      "Accuracy on Test-Set: 75.77% (7577 / 10000)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "x, y, output, y_pred_cls, global_step, learning_rate = model()\n",
    "\n",
    "\n",
    "_BATCH_SIZE = 128\n",
    "_CLASS_SIZE = 10\n",
    "_SAVE_PATH = \"./tensorboard/cifar-10-v1.0.0/\"\n",
    "\n",
    "\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"\\nTrying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=_SAVE_PATH)\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except ValueError:\n",
    "    print(\"\\nFailed to restore checkpoint. Initializing variables instead.\")\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "def test_nn():\n",
    "    i = 0\n",
    "    predicted_class = np.zeros(shape=len(test_x), dtype=np.int)\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        predicted_class[i:j] = sess.run(y_pred_cls, feed_dict={x: batch_xs, y: batch_ys})\n",
    "        i = j\n",
    "\n",
    "    correct = (np.argmax(test_y, axis=1) == predicted_class)\n",
    "    acc = correct.mean() * 100\n",
    "    correct_numbers = correct.sum()\n",
    "    print()\n",
    "    print(\"Accuracy on Test-Set: {0:.2f}% ({1} / {2})\".format(acc, correct_numbers, len(test_x)))\n",
    "\n",
    "\n",
    "test_nn()\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Опишите, что Вы делали \n",
    "В приведенной ниже ячейке вы должны  объяснить, что вы делали, какие-либо дополнительные особенности, которые вы использовали, и / или любые графики, которые вы получили в процессе обучения и тестирования сети."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАДАНИЕ: Опишите, что Вы делали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была построена модель сети\n",
    "\n",
    "----\n",
    "- conv\n",
    "- conv\n",
    "- pool\n",
    "- drop\n",
    "----\n",
    "- conv\n",
    "- pool\n",
    "- conv\n",
    "- pool\n",
    "- drop\n",
    "----\n",
    "- fc\n",
    "- drop\n",
    "- softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
