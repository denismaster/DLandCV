{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использвание признаков изображений \n",
    "Заполните этот блокнот, выполните код и защитите результаты. Полностью заполненный блокнот необходимо сохранить в электронном виде, передав его копию преподавателю, ведущему занятия. \n",
    "\n",
    "Мы видели, что мы можем достичь обоснованной эффективности решения задачи классификации изображений путем обучения линейного классификатора, используя пиксели входного изображения. В этом задании мы повысим эффективность классификации  путем обучения линейных классификаторов не на исходным пикселях, а на основе признаков, которые вычисляются в ходе анализа изображений.\n",
    "\n",
    "Все решения этого задания будут выполняться непосредственно в этом блокноте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # установка размеров графиков по умолчанию\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# для перезагрузки внешних модули python;\n",
    "# см. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Аналочно предыдущим заданиям, загрузим базу CIFAF-10 c диска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.features import color_histogram_hsv, hog_feature\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # выборка данных\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# Очистка переменных для предотвращения повторной загрузки данных\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение признаков\n",
    "\n",
    "Для каждого изображения будем вычислять гистограмму ориентированных градиентов (HOG), а также гистограмму цветов (HOC) с использованием шкалы оттенков цветового пространства HSV. Конечный вектор признаков для каждого изображения формируется путем конкатенации векторов гистограмм HOG и HOC.\n",
    "\n",
    "Приближенно, HOG  фиксирует текстуру изображения, игнорируя цветовую информацию, а гистограмма цветов фиксирует рапределение цветов изображения при игнорировании текстуры. В результате мы ожидаем, что совместное использование 2-х гистограмм должно работать лучше. Проверка этого предположения и есть цель этого задания.\n",
    "\n",
    "Функции `hog_feature` и` color_histogram_hsv` работают с одним и тем же\n",
    "изображением и возвращают вектор признаков для этого изображения. Функция `extract_features`\n",
    "вопринимает множество изображений и список признаковых функций и применяет каждую функцию  к изображению, сохраняя результаты в матрице, где каждый столбец является конкатенацией всех векторов признаков для одного изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.features import *\n",
    "\n",
    "num_color_bins = 10 # число столбцов гистограммы НОС\n",
    "feature_fns = [hog_feature, lambda img: color_histogram_hsv(img, nbin=num_color_bins)]\n",
    "X_train_feats = extract_features(X_train, feature_fns, verbose=True)\n",
    "X_val_feats = extract_features(X_val, feature_fns)\n",
    "X_test_feats = extract_features(X_test, feature_fns)\n",
    "\n",
    "# Предобработка: Вычитание среднего признака\n",
    "mean_feat = np.mean(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats -= mean_feat\n",
    "X_val_feats -= mean_feat\n",
    "X_test_feats -= mean_feat\n",
    "\n",
    "# Предобработка: Деление на стандартное отклонеине. Это обеспечивает для каждого признака\n",
    "# примерно один и тот же масштаб.\n",
    "std_feat = np.std(X_train_feats, axis=0, keepdims=True)\n",
    "X_train_feats /= std_feat\n",
    "X_val_feats /= std_feat\n",
    "X_test_feats /= std_feat\n",
    "\n",
    "# Предобработка: Разширение размера для добавления смещения\n",
    "X_train_feats = np.hstack([X_train_feats, np.ones((X_train_feats.shape[0], 1))])\n",
    "X_val_feats = np.hstack([X_val_feats, np.ones((X_val_feats.shape[0], 1))])\n",
    "X_test_feats = np.hstack([X_test_feats, np.ones((X_test_feats.shape[0], 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение SVM классификатора на признаках изображений\n",
    "\n",
    "Используя многоклассовый SVM классификатор, разработанный ранее, обучите его с использованием признаков извлеченных из изображений выше; результаты классификации должны быть лучше, чем  при обучении SVM непосредственно с использованием пикселей изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте валидационное множество для выбора скорости обучения и коэффициента регуляризации\n",
    "from cs231n.classifiers.linear_classifier import LinearSVM\n",
    "\n",
    "learning_rates = [1e-9, 1e-8, 1e-7]\n",
    "regularization_strengths = [5e4, 5e5, 5e6]\n",
    "\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_svm = None\n",
    "\n",
    "################################################################################\n",
    "# ЗАДАНИЕ:                                                                     #\n",
    "# Используйте валидационное множество для выбора скорости обучения и           #\n",
    "# коэффициента регуляризации. Это аналогично валидации, которую вы делали      #\n",
    "# для SVM классификатора; сохраните наилучший классификатор  в best_svm.       #\n",
    "# Вы также можете варьировать число столбцов гистограммы цветов. При           # \n",
    "# тщательном обучении вы должны получить валидацинную точность около 0.44.     #\n",
    "################################################################################\n",
    "################################################################################\n",
    "#                              КОНЕЦ ВАШЕГО КОДА                               #\n",
    "################################################################################\n",
    "\n",
    "# Вывод результатов.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка обученного классификатора на тестовом множесте\n",
    "y_test_pred = best_svm.predict(X_test_feats)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Важным способом развития интуиции в отношении понимания работы алгоритма является\n",
    "# визуализуализация ошибок, которые он совершает. Визуализация ниже демонстрирует примеры\n",
    "# изображений, которые неправильно классифицируются текущей версией программы. Первый столбец\n",
    "# показывает изображения, которым программа  присвоила метку «самолет», но чьи настоящие метки\n",
    "# таковыми не являются.\n",
    "\n",
    "examples_per_class = 8\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for cls, cls_name in enumerate(classes):\n",
    "    idxs = np.where((y_test != cls) & (y_test_pred == cls))[0]\n",
    "    idxs = np.random.choice(idxs, examples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt.subplot(examples_per_class, len(classes), i * len(classes) + cls + 1)\n",
    "        plt.imshow(X_test[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопрос 1:\n",
    "\n",
    "Опишите результаты ошибочной классификации, которые Вы наблюдаете. Они имеют обоснование?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение нейросети на признаках изображений\n",
    " \n",
    "Ранее Вы видели, что  двухслойная нейронная сеть, обучаемая  непосредственно на пикселях изображения, обеспечивала более высокую точность классификации, чем линейные классификаторы. Выше Вы также установили, что линейные классификаторы, обучаемые на  признаках изображений, превосходят линейные классификаторы, обучаемые на \"сырых\" пикселях.\n",
    "\n",
    "Для полноты исследований необходимо обучить нейронную сеть на признаках изображений. Такая сеть  должна дать лучшие результаты: вы должны легко получить точность классификации более 55%  на тестовом множестве; наша лучшая модель обладала  точностью  классификации около 60% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка: Удаление измерения смещения\n",
    "# Эта ячейка блокнота должна выполняться только один  раз!\n",
    "print(X_train_feats.shape)\n",
    "X_train_feats = X_train_feats[:, :-1]\n",
    "X_val_feats = X_val_feats[:, :-1]\n",
    "X_test_feats = X_test_feats[:, :-1]\n",
    "\n",
    "print(X_train_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "input_dim = X_train_feats.shape[1]\n",
    "hidden_dim = 500\n",
    "num_classes = 10\n",
    "\n",
    "net = TwoLayerNet(input_dim, hidden_dim, num_classes)\n",
    "best_net = None\n",
    "\n",
    "################################################################################\n",
    "# ЗАДАНИЕ: Обучите 2-х слойную нейросеть на признаках изображений. Выполните   #\n",
    "# кросс-валидацию различных парметров, аналогично предыдущим разделам.         #\n",
    "# Сохраните вашу лучшую модель нейросети в переменной best_net.                #            \n",
    "################################################################################\n",
    "# Ваш код\n",
    "################################################################################\n",
    "#                              КОНЕЦ ВАШЕГО КОДА                               #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверьте Вашу лучшую модель на тестовом множестве. Вы должы получить\n",
    "# точность классификации более 55%\n",
    "\n",
    "test_acc = (best_net.predict(X_test_feats) == y_test).mean()\n",
    "print(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
