{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование модели нейронной сети\n",
    "В этой части лабораторных заданий  мы разработаем полносвязанную нейронную сеть для классификации изображений из базы данных CIFAR-10 и выполним проверку нейросети на тестовом множестве "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Установки\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "# Для перезагрузки внешних модулей python;\n",
    "# см. http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать класс `TwoLayerNet` из файла` cs231n / классификаторы / neural_net.py` для представления экземпляров сети. Параметры сети хранятся в переменной класса `self.params`, где ключи являются строковыми именами параметров, а значения - массивами numpy. Ниже мы создадим отладочный набор данных и одладочную модель, которые будем использовать в ходе разработки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание  небольшой сети и набора отладочных данных для проверки реализаций.\n",
    "# Обратите внимание, что мы задаём seed  для повторяемости экспериментов.\n",
    "\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "    np.random.seed(0)\n",
    "    return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "    np.random.seed(1)\n",
    "    X = 10 * np.random.randn(num_inputs, input_size)\n",
    "    y = np.array([0, 1, 2, 2, 1])\n",
    "    return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прямой путь: вычисление scores (рейтингов)\n",
    "\n",
    "Откройте файл `cs231n/classifiers/neural_net.py` и просмотрите метод` TwoLayerNet.loss`. Эта функция очень похожа на функции, которые вы писали при реализации  SVM и Softmax классификаторов: она получает на вход  данные и веса и вычисляет рейтинги классов, потери и градиенты функции потерь.\n",
    "\n",
    "Выполните первую часть прямого прохода по сети, которая использует веса и смещения, чтобы вычисленить рейтинги классов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = net.loss(X)\n",
    "print('Your scores:')\n",
    "print(scores)\n",
    "print()\n",
    "print('correct scores:')\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print(correct_scores)\n",
    "print()\n",
    "\n",
    "# Разность должна быть < 1e-7\n",
    "print('Difference between your scores and correct scores:')\n",
    "print(np.sum(np.abs(scores - correct_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прямой путь: вычисление потерь\n",
    "\n",
    "В той же функции реализуйте вторую часть, которая вычисляет потери на данных и потери регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.05)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# разность должна быть < 1e-12\n",
    "print('Difference between your loss and correct loss:')\n",
    "print(np.sum(np.abs(loss - correct_loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обратное распространение\n",
    "Реализуйте оставшуюся часть функции. Она должна вычислять градиент функции потерь по переменным `W1`, `b1`, `W2`, и `b2`. Теперь, когда у Вас есть корректно реализванное прямое распространение, Вы можете отладить обратное распространение, используя проверку численного градиента. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "# Используйте численную проверку градиента, чтобы проверить вашу реализацию обратного пути.\n",
    "# Если ваша реализация верна, разница между численным и\n",
    "# аналитическим градиентом должны быть меньше 1е-8 для каждого из параметров: W1, W2, b1 и b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.05)\n",
    "\n",
    "# относительная ошибка должна быть меньше или примерно 1e-8\n",
    "for param_name in grads:\n",
    "    f = lambda W: net.loss(X, y, reg=0.05)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "    print('%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение сети\n",
    "\n",
    "Для обучения сети будем использовать стохастический градиентный спуск (SGD), аналогичный классификаторам SVM и Softmax. Просмотрите на функцию `TwoLayerNet.train` и заполните отсутствующие части, реализующие процедуры обучения. Это должно очень похоже на процедуру обучения, которую Вы использовали для классификаторов SVM и Softmax. Вам также придется реализовать «TwoLayerNet.predict», поскольку процесс обучения периодически выполняет предсказание, чтобы отслеживать точность в ходе итераций.\n",
    "\n",
    "После того, как Вы реализуете этот метод, запустите приведенный ниже код для обучения двухслойной сети на отладочных данных. Вы должны достичь значения потерь обучения менее 0,2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=5e-6,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print('Final training loss: ', stats['loss_history'][-1])\n",
    "\n",
    "# отображение функции потерь\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных\n",
    "Теперь, когда Вы реализовали двухслойную сеть, которая проходит проверку градиента и работает с отладочными данными, пришло время загрузить базу CIFAR-10, чтобы мы могли использовать ее для обучения классификатора на реальном наборе данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Загружает набор данных CIFAR-10 с диска и выполняет их предварительную \n",
    "    обработку для подачи на вход двухслойного нейронного классификатора. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Загрузка базы CIFAR-10 \n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Выборка данных\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Нормализация данных: вычитание среднего изображения\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Вытягивание матриц в векторы\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "# Очистка переменных для предотвращения повторной загрузки данных (что может вызвать проблемы с памятью)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Вызов функции, определенной выше, для получения данных.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение сети\n",
    "To train our network we will use SGD. In addition, we will adjust the learning rate with an exponential learning rate schedule as optimization proceeds; after each epoch, we will reduce the learning rate by multiplying it by a decay rate.\n",
    "Для обучения нашей сети будем использовать алгоритм SGD. Кроме того, будем управлять скоростью обучения с ппутём её экспоненциального затухания в процессе оптимизации; после каждой эпохи будем уменьшать скорость обучения, умножая ее на коэффициент затухания (decay rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Обучение сети\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.25, verbose=True)\n",
    "\n",
    "# Предсказание на валидационном множестве\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print('Validation accuracy: ', val_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отладка процесса обучения\n",
    "\n",
    "Используя приведенные выше параметры по умолчанию, вы должны получить на валидационном множестве точность, равную примерно 0.29. Это не очень хорошо.\n",
    "\n",
    "Одна из стратегий получения информации о том, что не так, заключается в построении функции потерь и точности на обучающем и валидационном множествах в ходе оптимизации.\n",
    "\n",
    "Другая стратегия - визуализировать обученные веса первого слоя сети. В большинстве нейронных сетей, обучающихся по изображениям, веса первого слоя обычно демонстрирует некоторую визуализируемую структуру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отображение функции потерь и точности обучения/валидации\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cs231n.vis_utils import visualize_grid\n",
    "\n",
    "# Визуализация весов нейронной сети\n",
    "\n",
    "def show_net_weights(net):\n",
    "    W1 = net.params['W1']\n",
    "    W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "    plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выбор гиперпараметров\n",
    "\n",
    "\n",
    "**В чем проблема?**. Рассматривая визуализацию выше, мы видим, что потери уменьшаются более или менее линейно, что, по-видимому, указывает на то, что возможно скорость обучения слишком низкая. Более того, нет разрыва между точностью обучения и валидационной точностью, т.е. используемая нами модель имеет малую емкость и  мы должны увеличить число параметров модели. С другой стороны, при большом числе параметров возможно переобучение, которое проявляется в виде большого разрыва между точностью обучения и точностью валидации.\n",
    "\n",
    "**Настройка**. Выбор гиперпараметров и развитие интуиции в отношении того, как они влияют на конечную эффективность, - это большая часть навыков применения нейросетей, поэтому мы хотим, чтобы Вы получили больше практики. Ниже Вы должны поэкспериментировать с различными значениями гиперпараметров, включая размер скрытого слоя, скорость обучения, количество эпох обучения и коэффициент регуляризации. Вы также можете рассмотреть возможность выбора коэффициента затухания скорости обучения, но Вы должны также получать хорошие результаты и при использовании значений по умолчанию.\n",
    "\n",
    "**Примерные результаты**. Вы должны стремиться к достижению точности классификации, превышающей 48% валидационном множестве. Наша лучшая сеть имела точность более 52% в ходе валидации.\n",
    "\n",
    "**Эксперимент**: Цель этого задания - получить как можно лучшие результаты на данных CIFAR-10 при использовании полносвязаной нейронной сети. Не стесняйтесь применять свои собственные методы (например, PCA, чтобы уменьшить размерность, или dropout или использовать признаки изображений т. д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = None # здесь запоминаем наилучшую модель \n",
    "\n",
    "#################################################################################\n",
    "# ЗАДАНИЕ: Выполните выбор гиперпараметров, используя множество валидации.      #\n",
    "# Сохраните Вашу лучшую модель в  best_net.                                     #                                                           #\n",
    "#                                                                               #\n",
    "# Чтобы отладить вашу сеть, полезно использовать визуализацию, похожую на       #\n",
    "# ту, которую мы использовали выше; эта визуализация будет иметь значительные   #\n",
    "# качественные отличия от той,которую мы видели выше для плохо настроенной сети.#\n",
    "#                                                                               #\n",
    "# Настройка гиперпараметров вручную может быть интересной и может показаться    #\n",
    "# Вам занимательной, но лучше написать код для перебора возможных комбинаций    #\n",
    "# гиперпараметров, как мы делали это в предыдущих заданиях.                     #\n",
    "#################################################################################\n",
    "# Ваш код\n",
    "#################################################################################\n",
    "#                               КОНЕЦ ВАШЕГО КОДА                               #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# визуализация весов лучшей сети\n",
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение на тестовом множестве данных\n",
    "Когда вы закончите экспериментирование, вы должны оценить окончательно обученную сеть на тестовом наборе; вы должны получить точность более 48%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print('Test accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вопрос**\n",
    "\n",
    "Now that you have trained a Neural Network classifier, you may find that your testing accuracy is much lower than the training accuracy. In what ways can we decrease this gap? Select all that apply.\n",
    "1. Train on a larger dataset.\n",
    "2. Add more hidden units.\n",
    "3. Increase the regularization strength.\n",
    "4. None of the above.\n",
    "\n",
    "Теперь, когда Вы обучили нейроклассификатор, вы можете обнаружить, что точность тестирования намного ниже, чем точность обучения. Каким образом мы можем уменьшить этот разрыв? Выбрать все ответы, которые подходят.\n",
    "1. Обучать на большем наборе данных.\n",
    "2. Добавить больше скрытых слоев.\n",
    "3. Увеличить коэффициент регуляризации.\n",
    "4. Ничего из перечисленного.\n",
    "\n",
    "*Ваш ответ*:\n",
    "\n",
    "*Ваши объяснения:*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
